{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea code name: `S1P10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, LSTM, PReLU, Reshape, Dropout, Activation\n",
    "from keras.models import model_from_json, Model\n",
    "import keras\n",
    "\n",
    "from s1p10_model.resnet8_body import resnet8_body\n",
    "\n",
    "from s1p10_training_utils import save_lstm, DataGenerator\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weight of each angle class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./s1p10_data/s1p10_classes_weight.json', 'r') as fp:\n",
    "    classes_weight = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load bins edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_edge = np.load('./s1p10_data/s1p10_bins_edge.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (200, 200, 1)\n",
    "NUM_CLASSES = len(classes_weight)\n",
    "NUM_PREDICT = 5\n",
    "LSTM_NUM_HIDDEN_STATE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model acrchitect\n",
    "\n",
    "1 Image -> ResNet-8 -> LSTM_1 -> LSTM_2 (return state = True) (use this to sample prediction) -> Dense + Softmax \n",
    "-> 10 steering angle ID\n",
    "\n",
    "## 1.2 Create Encoder\n",
    "Encoder is body of ResNet-8 from `Drone-Net` since it's already trained to recognize road curve -> helpful spatial information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py:210: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv2D)                 (None, 100, 100, 32) 832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 49, 49, 32)   0           conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_a (BatchNormalization)     (None, 49, 49, 32)   128         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 49, 49, 32)   0           bn_1_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_a (Conv2D)               (None, 25, 25, 32)   9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_b (BatchNormalization)     (None, 25, 25, 32)   128         conv_1_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 25, 25, 32)   0           bn_1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_b (Conv2D)               (None, 25, 25, 32)   9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_c (Conv2D)               (None, 25, 25, 32)   1056        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 25, 32)   0           conv_1_b[0][0]                   \n",
      "                                                                 conv_1_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_a (BatchNormalization)     (None, 25, 25, 32)   128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 25, 25, 32)   0           bn_2_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_a (Conv2D)               (None, 13, 13, 64)   18496       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_b (BatchNormalization)     (None, 13, 13, 64)   256         conv_2_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 13, 13, 64)   0           bn_2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_b (Conv2D)               (None, 13, 13, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_c (Conv2D)               (None, 13, 13, 64)   2112        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 13, 13, 64)   0           conv_2_b[0][0]                   \n",
      "                                                                 conv_2_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_3_a (BatchNormalization)     (None, 13, 13, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 13, 13, 64)   0           bn_3_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_a (Conv2D)               (None, 7, 7, 128)    73856       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_3_b (BatchNormalization)     (None, 7, 7, 128)    512         conv_3_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 128)    0           bn_3_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_b (Conv2D)               (None, 7, 7, 128)    147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_c (Conv2D)               (None, 7, 7, 128)    8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 7, 7, 128)    0           conv_3_b[0][0]                   \n",
      "                                                                 conv_3_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6272)         0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 6272)         0           flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 309,088\n",
      "Trainable params: 0\n",
      "Non-trainable params: 309,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = resnet8_body(IMAGE_SHAPE)\n",
    "# load resnet8 weights\n",
    "encoder.load_weights(\"./s1p10_model/named_resnet8_best_weights.h5\", by_name=True)\n",
    "for l in encoder.layers:\n",
    "    l.trainable = False\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Create Decoder\n",
    "Decoder is comprised of 2 LSTM & 2 Dense layers, last Dense layer is activated by Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_cell = LSTM(LSTM_NUM_HIDDEN_STATE, \n",
    "                 return_state=True, \n",
    "                 kernel_regularizer=keras.regularizers.l2(1e-2))  # use to sample angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_classifier(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Define classifier made of several Dense layers\n",
    "    \"\"\"\n",
    "    X_in = Input(shape=input_shape)\n",
    "    \n",
    "    X = Dense(128, kernel_regularizer=keras.regularizers.l2(1e-2))(X_in)\n",
    "    \n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    X = Activation('relu')(X)  # past use PReLU activation\n",
    "    \n",
    "    X = Dense(64, kernel_regularizer=keras.regularizers.l2(1e-2))(X)\n",
    "    \n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    X = Activation('relu')(X)  # past PReLU\n",
    "    \n",
    "    y = Dense(num_classes, activation='softmax', kernel_regularizer=keras.regularizers.l2(1e-2))(X)\n",
    "    \n",
    "    model = Model(inputs=[X_in], outputs=[y], name='classifier')\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "classifier = dense_classifier((LSTM_NUM_HIDDEN_STATE, ), NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 114)               7410      \n",
      "=================================================================\n",
      "Total params: 32,178\n",
      "Trainable params: 32,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s1p10_model(input_shape, encoder, LSTM_cell, classifier, lstm_num_hidden_state, num_classes, num_labels):\n",
    "    \"\"\"\n",
    "    Define see-1-predict-10 model\n",
    "    \n",
    "    Input:\n",
    "        input_shape (tuple): shape of input image inputted to encoder\n",
    "        encoder (keras.Model)\n",
    "        LSTM_cell (keras.layers)\n",
    "        classifier (keras.Model)\n",
    "        \n",
    "    Output:\n",
    "        keras.Model\n",
    "    \"\"\"\n",
    "    X_in = Input(shape=input_shape, name=\"image_in\")\n",
    "    \n",
    "    # extract feature vector\n",
    "    X_feature = encoder(X_in)\n",
    "    X_feature = Reshape((1, -1))(X_feature)  # shape = (None, 1, 6272)\n",
    "    \n",
    "    # Initialize input to LSTM\n",
    "    a0 = Input(shape=(LSTM_NUM_HIDDEN_STATE, ), name=\"a0\")\n",
    "    c0 = Input(shape=(LSTM_NUM_HIDDEN_STATE, ), name=\"c0\")\n",
    "    y0 = Input(shape=(num_classes, ), name=\"y0\")  # will be concatenated with X_feature to make X\n",
    "    \n",
    "    a = a0\n",
    "    c = c0\n",
    "    y = y0\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    for i in range(num_labels):\n",
    "        # concatenate y & X_feature\n",
    "        y = Reshape((1, -1))(y)\n",
    "        \n",
    "        X_drop = Dropout(0.5)(X_feature)\n",
    "        \n",
    "        X = keras.layers.concatenate([X_drop, y], axis=-1)\n",
    "        # propagate X through LSTM_cell\n",
    "        a, _, c = LSTM_cell(X, initial_state=[a, c])\n",
    "        # propagate hidden state \"a\" through classifier to get steering angle\n",
    "        y = classifier(a)\n",
    "        # store y\n",
    "        outputs.append(y)\n",
    "    \n",
    "    model = Model(inputs=[X_in, a0, c0, y0], outputs=outputs)\n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_in (InputLayer)           (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet8 (Model)                 (None, 6272)         309088      image_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 6272)      0           resnet8[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "y0 (InputLayer)                 (None, 114)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1, 6272)      0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 114)       0           y0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 6386)      0           dropout_3[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "a0 (InputLayer)                 (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 128), (None, 3335680     concatenate_1[0][0]              \n",
      "                                                                 a0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[2][2]                     \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[3][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "classifier (Model)              (None, 114)          32178       lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1, 6272)      0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 114)       0           classifier[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 6386)      0           dropout_4[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1, 6272)      0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 114)       0           classifier[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1, 6386)      0           dropout_5[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1, 6272)      0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 114)       0           classifier[3][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1, 6386)      0           dropout_6[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1, 6272)      0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 114)       0           classifier[4][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1, 6386)      0           dropout_7[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,676,946\n",
      "Trainable params: 3,367,858\n",
      "Non-trainable params: 309,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = s1p10_model(IMAGE_SHAPE, \n",
    "                    encoder, \n",
    "                    LSTM_cell, \n",
    "                    classifier, \n",
    "                    LSTM_NUM_HIDDEN_STATE, \n",
    "                    NUM_CLASSES, \n",
    "                    NUM_PREDICT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adadelta', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "gen_param = {'data_root_dir': \"/home/user/Bureau/Dataset/udacity/\", \n",
    "             'img_shape': IMAGE_SHAPE, \n",
    "             'num_class': NUM_CLASSES, \n",
    "             'num_prediction': NUM_PREDICT, \n",
    "             'bins_edge': bins_edge,\n",
    "             'batch_size': batch_size, \n",
    "             'shuffle': True, \n",
    "             'lstm_dim_hidden_states': LSTM_NUM_HIDDEN_STATE,\n",
    "             'flip_prob': 0.5}\n",
    "\n",
    "train_gen = DataGenerator(\"./s1p10_data/s1p10_CH2_002_output_training.csv\", **gen_param)\n",
    "val_gen = DataGenerator(\"./s1p10_data/s1p10_CH2_002_output_validation.csv\", **gen_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = time.strftime(\"%Y_%m_%d_%H_%M\")\n",
    "log_dir = './s1p10_logs/' + time_str\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir=log_dir,  \n",
    "                                          batch_size=batch_size, \n",
    "                                          update_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3067: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "284/284 [==============================] - 139s 489ms/step - loss: 19.1013 - classifier_loss: 3.1394 - classifier_acc: 0.2080 - classifier_acc_1: 0.2120 - classifier_acc_2: 0.2097 - classifier_acc_3: 0.2076 - classifier_acc_4: 0.2096 - val_loss: 18.8143 - val_classifier_loss: 3.4440 - val_classifier_acc: 0.2339 - val_classifier_acc_1: 0.2312 - val_classifier_acc_2: 0.2307 - val_classifier_acc_3: 0.2261 - val_classifier_acc_4: 0.2281\n",
      "Epoch 2/3\n",
      "284/284 [==============================] - 135s 477ms/step - loss: 15.3612 - classifier_loss: 2.8403 - classifier_acc: 0.2341 - classifier_acc_1: 0.2306 - classifier_acc_2: 0.2288 - classifier_acc_3: 0.2268 - classifier_acc_4: 0.2316 - val_loss: 18.5085 - val_classifier_loss: 3.4491 - val_classifier_acc: 0.2285 - val_classifier_acc_1: 0.2190 - val_classifier_acc_2: 0.2120 - val_classifier_acc_3: 0.2064 - val_classifier_acc_4: 0.2043\n",
      "Epoch 3/3\n",
      "284/284 [==============================] - 136s 480ms/step - loss: 14.7135 - classifier_loss: 2.7187 - classifier_acc: 0.2350 - classifier_acc_1: 0.2381 - classifier_acc_2: 0.2384 - classifier_acc_3: 0.2372 - classifier_acc_4: 0.2353 - val_loss: 18.4522 - val_classifier_loss: 3.4346 - val_classifier_acc: 0.2017 - val_classifier_acc_1: 0.1957 - val_classifier_acc_2: 0.1921 - val_classifier_acc_3: 0.1931 - val_classifier_acc_4: 0.1928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f36cc84eef0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    class_weight=classes_weight,\n",
    "                    epochs=3,\n",
    "                    validation_data=val_gen,\n",
    "                    initial_epoch=0,\n",
    "                    callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save shared_lstm\n",
    "save_lstm(LSTM_cell, time_str, log_dir)\n",
    "\n",
    "# save classifier\n",
    "classifier.save_weights(log_dir + \"/classifier_%s.h5\" % time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019_05_27_18_31'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
