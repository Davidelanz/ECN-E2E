{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea code name: `S1P10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, LSTM, PReLU, Reshape, Dropout, Activation, BatchNormalization, Lambda\n",
    "from keras.models import model_from_json, Model\n",
    "import keras.backend as K\n",
    "from keras import regularizers\n",
    "import keras\n",
    "\n",
    "from s1p10_model.resnet8_body import resnet8_body\n",
    "\n",
    "from s1p10_training_utils import gen_classifier_dataset\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (200, 200, 1)\n",
    "NUM_LABELS = 5\n",
    "BINS_EDGE = np.load(\"./s1p10_data/s1p10_bins_edge.npy\")\n",
    "NUM_CLASSES = len(BINS_EDGE) - 1  \n",
    "\n",
    "with open('./s1p10_data/s1p10_classes_weight.json', 'r') as fp:\n",
    "    CLASSES_WEIGHT = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model Acrchitect\n",
    "\n",
    "1 Image -> ResNet-8 -> Dense regressor -> 5 steering angles\n",
    "\n",
    "## 1.2 Create Encoder\n",
    "Encoder is body of ResNet-8 from `Drone-Net` since it's already trained to recognize road curve -> helpful spatial information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py:210: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv2D)                 (None, 100, 100, 32) 832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 49, 49, 32)   0           conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_a (BatchNormalization)     (None, 49, 49, 32)   128         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 49, 49, 32)   0           bn_1_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_a (Conv2D)               (None, 25, 25, 32)   9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_b (BatchNormalization)     (None, 25, 25, 32)   128         conv_1_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 25, 25, 32)   0           bn_1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_b (Conv2D)               (None, 25, 25, 32)   9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_c (Conv2D)               (None, 25, 25, 32)   1056        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 25, 32)   0           conv_1_b[0][0]                   \n",
      "                                                                 conv_1_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_a (BatchNormalization)     (None, 25, 25, 32)   128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 25, 25, 32)   0           bn_2_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_a (Conv2D)               (None, 13, 13, 64)   18496       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_b (BatchNormalization)     (None, 13, 13, 64)   256         conv_2_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 13, 13, 64)   0           bn_2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_b (Conv2D)               (None, 13, 13, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_c (Conv2D)               (None, 13, 13, 64)   2112        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 13, 13, 64)   0           conv_2_b[0][0]                   \n",
      "                                                                 conv_2_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_3_a (BatchNormalization)     (None, 13, 13, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 13, 13, 64)   0           bn_3_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_a (Conv2D)               (None, 7, 7, 128)    73856       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_3_b (BatchNormalization)     (None, 7, 7, 128)    512         conv_3_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 128)    0           bn_3_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_b (Conv2D)               (None, 7, 7, 128)    147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_c (Conv2D)               (None, 7, 7, 128)    8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 7, 7, 128)    0           conv_3_b[0][0]                   \n",
      "                                                                 conv_3_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6272)         0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 6272)         0           flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 309,088\n",
      "Trainable params: 308,384\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = resnet8_body(IMAGE_SHAPE)\n",
    "# load resnet8 weights\n",
    "encoder.load_weights(\"./s1p10_model/named_resnet8_best_weights.h5\", by_name=True)\n",
    "# for l in encoder.layers:\n",
    "#     l.trainable = False\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Create Decoder\n",
    "Decoder is a seri of Dense layers with a non-activate Dense layer at the end to perform regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshapor = Reshape((1, -1))\n",
    "\n",
    "def s1p10_model(input_shape):\n",
    "    \"\"\"\n",
    "    Define see-1-predict-10 model\n",
    "    \n",
    "    Input:\n",
    "        input_shape (tuple): shape of input image inputted to encoder\n",
    "        \n",
    "    Output:\n",
    "        keras.Model\n",
    "    \"\"\"\n",
    "    X_in = Input(shape=input_shape, name=\"image_in\")\n",
    "    \n",
    "    # extract feature vector\n",
    "    X_feature = encoder(X_in)\n",
    "    X_feature = Dropout(0.5)(X_feature)\n",
    "    \n",
    "    # apply classifier body\n",
    "    X_body = Dense(800, activation='relu')(X_feature)\n",
    "    \n",
    "    # apply classifier head\n",
    "    y = []\n",
    "    for i in range(NUM_LABELS): \n",
    "        out = Dense(NUM_CLASSES, activation='softmax', name=\"head_%d\" % i)(X_body)\n",
    "        y.append(out)\n",
    "    \n",
    "#     # apply classifier head\n",
    "#     class_neck = []\n",
    "#     for i in range(NUM_LABELS):\n",
    "#         X = Dense(300, activation='relu', name=\"neck_%d\" % i)(X_body)\n",
    "#         X = reshapor(X)\n",
    "#         class_neck.append(X)\n",
    "    \n",
    "#     # apply LSTM\n",
    "#     X = keras.layers.concatenate(class_neck, axis=1)  # to get shape (None, 5, 300)\n",
    "#     X = LSTM(128, return_sequences=True, dropout=0.5)(X)\n",
    "    \n",
    "#     # apply classifier head\n",
    "#     y = []\n",
    "#     for i in range(NUM_LABELS):\n",
    "#         X_neck = Lambda(lambda X : X[:, i, :])(X)\n",
    "#         X = Dropout(0.5)(X)\n",
    "#         out = Dense(NUM_CLASSES, activation=\"softmax\", name=\"head_%d\" % i)(X_neck)\n",
    "#         y.append(out)\n",
    "    \n",
    "    model = Model(inputs=[X_in], outputs=y)\n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_in (InputLayer)           (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet8 (Model)                 (None, 6272)         309088      image_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 6272)         0           resnet8[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 800)          5018400     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "head_0 (Dense)                  (None, 114)          91314       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "head_1 (Dense)                  (None, 114)          91314       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "head_2 (Dense)                  (None, 114)          91314       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "head_3 (Dense)                  (None, 114)          91314       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "head_4 (Dense)                  (None, 114)          91314       dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,784,058\n",
      "Trainable params: 5,783,354\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = s1p10_model(IMAGE_SHAPE)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss=\"categorical_crossentropy\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_param = {'num_classes': NUM_CLASSES, \n",
    "             'num_labels': NUM_LABELS, \n",
    "             'bins_edge': BINS_EDGE, \n",
    "             'image_shape': IMAGE_SHAPE, \n",
    "             'num_samples': 10, \n",
    "             'data_root_dir': \"/home/user/Bureau/Dataset/udacity/\", \n",
    "             'flip_prob': 0.5}\n",
    "\n",
    "# X_train, y_train = gen_classifier_dataset(\"./s1p10_data/s1p10_CH2_002_output_training.csv\", **gen_param)\n",
    "X_train = np.load('./s1p10_data/CH2_training_X.npy')\n",
    "y_train_arr = np.load('./s1p10_data/CH2_training_y.npy')  # shape (5, len_dataset, num_classes)\n",
    "y_train = [y_train_arr[i, :, :]for i in range(NUM_LABELS)]\n",
    "\n",
    "# X_val, y_val = gen_classifier_dataset(\"./s1p10_data/s1p10_CH2_002_output_validation.csv\", **gen_param)\n",
    "X_val = np.load('./s1p10_data/CH2_validation_X.npy')\n",
    "y_val_arr = np.load('./s1p10_data/CH2_validation_y.npy')\n",
    "y_val = [y_val_arr[i, :, :]for i in range(NUM_LABELS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3067: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 18232 samples, validate on 2026 samples\n",
      "Epoch 1/80\n",
      "18232/18232 [==============================] - 43s 2ms/step - loss: 19.0990 - head_0_loss: 3.7594 - head_1_loss: 3.8747 - head_2_loss: 3.7757 - head_3_loss: 3.9025 - head_4_loss: 3.7866 - head_0_acc: 0.1966 - head_1_acc: 0.1920 - head_2_acc: 0.1870 - head_3_acc: 0.1849 - head_4_acc: 0.1880 - val_loss: 14.0181 - val_head_0_loss: 2.8251 - val_head_1_loss: 2.8192 - val_head_2_loss: 2.7942 - val_head_3_loss: 2.8004 - val_head_4_loss: 2.7793 - val_head_0_acc: 0.2310 - val_head_1_acc: 0.2310 - val_head_2_acc: 0.2349 - val_head_3_acc: 0.2374 - val_head_4_acc: 0.2399\n",
      "Epoch 2/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 13.5255 - head_0_loss: 2.7272 - head_1_loss: 2.7038 - head_2_loss: 2.6891 - head_3_loss: 2.7067 - head_4_loss: 2.6987 - head_0_acc: 0.2391 - head_1_acc: 0.2402 - head_2_acc: 0.2434 - head_3_acc: 0.2383 - head_4_acc: 0.2396 - val_loss: 12.1822 - val_head_0_loss: 2.4690 - val_head_1_loss: 2.4391 - val_head_2_loss: 2.4165 - val_head_3_loss: 2.4429 - val_head_4_loss: 2.4147 - val_head_0_acc: 0.2675 - val_head_1_acc: 0.2813 - val_head_2_acc: 0.2962 - val_head_3_acc: 0.2843 - val_head_4_acc: 0.2912\n",
      "Epoch 3/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 12.3253 - head_0_loss: 2.4891 - head_1_loss: 2.4675 - head_2_loss: 2.4490 - head_3_loss: 2.4605 - head_4_loss: 2.4593 - head_0_acc: 0.2794 - head_1_acc: 0.2743 - head_2_acc: 0.2787 - head_3_acc: 0.2731 - head_4_acc: 0.2733 - val_loss: 11.4960 - val_head_0_loss: 2.3676 - val_head_1_loss: 2.3147 - val_head_2_loss: 2.2885 - val_head_3_loss: 2.2696 - val_head_4_loss: 2.2556 - val_head_0_acc: 0.3105 - val_head_1_acc: 0.3218 - val_head_2_acc: 0.3154 - val_head_3_acc: 0.3406 - val_head_4_acc: 0.3450\n",
      "Epoch 4/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 11.4334 - head_0_loss: 2.3253 - head_1_loss: 2.2943 - head_2_loss: 2.2669 - head_3_loss: 2.2691 - head_4_loss: 2.2778 - head_0_acc: 0.3011 - head_1_acc: 0.3050 - head_2_acc: 0.3125 - head_3_acc: 0.3068 - head_4_acc: 0.3096 - val_loss: 10.6131 - val_head_0_loss: 2.1784 - val_head_1_loss: 2.1369 - val_head_2_loss: 2.1045 - val_head_3_loss: 2.1077 - val_head_4_loss: 2.0856 - val_head_0_acc: 0.3638 - val_head_1_acc: 0.3578 - val_head_2_acc: 0.3687 - val_head_3_acc: 0.3786 - val_head_4_acc: 0.3702\n",
      "Epoch 5/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 10.6155 - head_0_loss: 2.1714 - head_1_loss: 2.1276 - head_2_loss: 2.0999 - head_3_loss: 2.1034 - head_4_loss: 2.1132 - head_0_acc: 0.3359 - head_1_acc: 0.3451 - head_2_acc: 0.3516 - head_3_acc: 0.3463 - head_4_acc: 0.3415 - val_loss: 9.6455 - val_head_0_loss: 1.9896 - val_head_1_loss: 1.9594 - val_head_2_loss: 1.9270 - val_head_3_loss: 1.9002 - val_head_4_loss: 1.8695 - val_head_0_acc: 0.4008 - val_head_1_acc: 0.3885 - val_head_2_acc: 0.4052 - val_head_3_acc: 0.4023 - val_head_4_acc: 0.4215\n",
      "Epoch 6/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 9.9358 - head_0_loss: 2.0524 - head_1_loss: 2.0043 - head_2_loss: 1.9631 - head_3_loss: 1.9566 - head_4_loss: 1.9594 - head_0_acc: 0.3631 - head_1_acc: 0.3689 - head_2_acc: 0.3789 - head_3_acc: 0.3771 - head_4_acc: 0.3813 - val_loss: 9.0444 - val_head_0_loss: 1.8906 - val_head_1_loss: 1.8212 - val_head_2_loss: 1.8176 - val_head_3_loss: 1.7744 - val_head_4_loss: 1.7405 - val_head_0_acc: 0.4121 - val_head_1_acc: 0.4334 - val_head_2_acc: 0.4319 - val_head_3_acc: 0.4418 - val_head_4_acc: 0.4620\n",
      "Epoch 7/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 9.2607 - head_0_loss: 1.9125 - head_1_loss: 1.8659 - head_2_loss: 1.8278 - head_3_loss: 1.8235 - head_4_loss: 1.8311 - head_0_acc: 0.3983 - head_1_acc: 0.4082 - head_2_acc: 0.4138 - head_3_acc: 0.4096 - head_4_acc: 0.4151 - val_loss: 8.4001 - val_head_0_loss: 1.7805 - val_head_1_loss: 1.7093 - val_head_2_loss: 1.6526 - val_head_3_loss: 1.6418 - val_head_4_loss: 1.6159 - val_head_0_acc: 0.4610 - val_head_1_acc: 0.4783 - val_head_2_acc: 0.4911 - val_head_3_acc: 0.4906 - val_head_4_acc: 0.4965\n",
      "Epoch 8/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 8.5994 - head_0_loss: 1.7864 - head_1_loss: 1.7258 - head_2_loss: 1.6893 - head_3_loss: 1.6937 - head_4_loss: 1.7043 - head_0_acc: 0.4319 - head_1_acc: 0.4424 - head_2_acc: 0.4546 - head_3_acc: 0.4505 - head_4_acc: 0.4495 - val_loss: 7.9125 - val_head_0_loss: 1.7081 - val_head_1_loss: 1.6204 - val_head_2_loss: 1.5528 - val_head_3_loss: 1.5352 - val_head_4_loss: 1.4960 - val_head_0_acc: 0.4669 - val_head_1_acc: 0.4872 - val_head_2_acc: 0.5168 - val_head_3_acc: 0.5183 - val_head_4_acc: 0.5321\n",
      "Epoch 9/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 8.0593 - head_0_loss: 1.6891 - head_1_loss: 1.6266 - head_2_loss: 1.5757 - head_3_loss: 1.5734 - head_4_loss: 1.5945 - head_0_acc: 0.4578 - head_1_acc: 0.4750 - head_2_acc: 0.4875 - head_3_acc: 0.4847 - head_4_acc: 0.4832 - val_loss: 7.6109 - val_head_0_loss: 1.6524 - val_head_1_loss: 1.5550 - val_head_2_loss: 1.4911 - val_head_3_loss: 1.4651 - val_head_4_loss: 1.4474 - val_head_0_acc: 0.5010 - val_head_1_acc: 0.5301 - val_head_2_acc: 0.5395 - val_head_3_acc: 0.5459 - val_head_4_acc: 0.5410\n",
      "Epoch 10/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 7.6263 - head_0_loss: 1.6034 - head_1_loss: 1.5448 - head_2_loss: 1.4821 - head_3_loss: 1.4900 - head_4_loss: 1.5061 - head_0_acc: 0.4844 - head_1_acc: 0.4929 - head_2_acc: 0.5139 - head_3_acc: 0.5090 - head_4_acc: 0.5130 - val_loss: 7.2822 - val_head_0_loss: 1.5825 - val_head_1_loss: 1.5011 - val_head_2_loss: 1.4138 - val_head_3_loss: 1.3961 - val_head_4_loss: 1.3887 - val_head_0_acc: 0.5262 - val_head_1_acc: 0.5395 - val_head_2_acc: 0.5548 - val_head_3_acc: 0.5632 - val_head_4_acc: 0.5597\n",
      "Epoch 11/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 7.1659 - head_0_loss: 1.5098 - head_1_loss: 1.4426 - head_2_loss: 1.3915 - head_3_loss: 1.4005 - head_4_loss: 1.4214 - head_0_acc: 0.5108 - head_1_acc: 0.5260 - head_2_acc: 0.5372 - head_3_acc: 0.5347 - head_4_acc: 0.5320 - val_loss: 6.9372 - val_head_0_loss: 1.5209 - val_head_1_loss: 1.4213 - val_head_2_loss: 1.3432 - val_head_3_loss: 1.3370 - val_head_4_loss: 1.3148 - val_head_0_acc: 0.5306 - val_head_1_acc: 0.5553 - val_head_2_acc: 0.5775 - val_head_3_acc: 0.5844 - val_head_4_acc: 0.5844\n",
      "Epoch 12/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 6.7572 - head_0_loss: 1.4253 - head_1_loss: 1.3697 - head_2_loss: 1.3101 - head_3_loss: 1.3138 - head_4_loss: 1.3382 - head_0_acc: 0.5366 - head_1_acc: 0.5491 - head_2_acc: 0.5657 - head_3_acc: 0.5602 - head_4_acc: 0.5595 - val_loss: 6.6655 - val_head_0_loss: 1.4556 - val_head_1_loss: 1.3599 - val_head_2_loss: 1.3079 - val_head_3_loss: 1.2752 - val_head_4_loss: 1.2669 - val_head_0_acc: 0.5652 - val_head_1_acc: 0.5933 - val_head_2_acc: 0.5888 - val_head_3_acc: 0.5992 - val_head_4_acc: 0.5933\n",
      "Epoch 13/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 6.3685 - head_0_loss: 1.3513 - head_1_loss: 1.2846 - head_2_loss: 1.2237 - head_3_loss: 1.2429 - head_4_loss: 1.2660 - head_0_acc: 0.5591 - head_1_acc: 0.5739 - head_2_acc: 0.5915 - head_3_acc: 0.5847 - head_4_acc: 0.5781 - val_loss: 6.3888 - val_head_0_loss: 1.4087 - val_head_1_loss: 1.3035 - val_head_2_loss: 1.2433 - val_head_3_loss: 1.2249 - val_head_4_loss: 1.2083 - val_head_0_acc: 0.5765 - val_head_1_acc: 0.5997 - val_head_2_acc: 0.6076 - val_head_3_acc: 0.6283 - val_head_4_acc: 0.6234\n",
      "Epoch 14/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 6.0310 - head_0_loss: 1.2928 - head_1_loss: 1.2192 - head_2_loss: 1.1538 - head_3_loss: 1.1637 - head_4_loss: 1.2014 - head_0_acc: 0.5810 - head_1_acc: 0.5893 - head_2_acc: 0.6104 - head_3_acc: 0.6047 - head_4_acc: 0.5991 - val_loss: 6.1641 - val_head_0_loss: 1.3563 - val_head_1_loss: 1.2817 - val_head_2_loss: 1.1902 - val_head_3_loss: 1.1759 - val_head_4_loss: 1.1600 - val_head_0_acc: 0.5923 - val_head_1_acc: 0.6007 - val_head_2_acc: 0.6422 - val_head_3_acc: 0.6347 - val_head_4_acc: 0.6293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 5.7187 - head_0_loss: 1.2249 - head_1_loss: 1.1459 - head_2_loss: 1.0951 - head_3_loss: 1.1035 - head_4_loss: 1.1493 - head_0_acc: 0.5981 - head_1_acc: 0.6191 - head_2_acc: 0.6311 - head_3_acc: 0.6270 - head_4_acc: 0.6136 - val_loss: 5.9882 - val_head_0_loss: 1.3069 - val_head_1_loss: 1.2217 - val_head_2_loss: 1.1547 - val_head_3_loss: 1.1555 - val_head_4_loss: 1.1494 - val_head_0_acc: 0.6037 - val_head_1_acc: 0.6214 - val_head_2_acc: 0.6333 - val_head_3_acc: 0.6500 - val_head_4_acc: 0.6283\n",
      "Epoch 16/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 5.3618 - head_0_loss: 1.1495 - head_1_loss: 1.0748 - head_2_loss: 1.0179 - head_3_loss: 1.0402 - head_4_loss: 1.0794 - head_0_acc: 0.6231 - head_1_acc: 0.6363 - head_2_acc: 0.6577 - head_3_acc: 0.6439 - head_4_acc: 0.6362 - val_loss: 5.7861 - val_head_0_loss: 1.2634 - val_head_1_loss: 1.1888 - val_head_2_loss: 1.1288 - val_head_3_loss: 1.1073 - val_head_4_loss: 1.0979 - val_head_0_acc: 0.6303 - val_head_1_acc: 0.6264 - val_head_2_acc: 0.6461 - val_head_3_acc: 0.6560 - val_head_4_acc: 0.6496\n",
      "Epoch 17/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 5.1586 - head_0_loss: 1.1069 - head_1_loss: 1.0394 - head_2_loss: 0.9816 - head_3_loss: 0.9935 - head_4_loss: 1.0373 - head_0_acc: 0.6332 - head_1_acc: 0.6520 - head_2_acc: 0.6709 - head_3_acc: 0.6587 - head_4_acc: 0.6501 - val_loss: 5.6394 - val_head_0_loss: 1.2375 - val_head_1_loss: 1.1545 - val_head_2_loss: 1.1061 - val_head_3_loss: 1.0702 - val_head_4_loss: 1.0710 - val_head_0_acc: 0.6357 - val_head_1_acc: 0.6481 - val_head_2_acc: 0.6589 - val_head_3_acc: 0.6807 - val_head_4_acc: 0.6599\n",
      "Epoch 18/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 4.9067 - head_0_loss: 1.0496 - head_1_loss: 0.9793 - head_2_loss: 0.9296 - head_3_loss: 0.9486 - head_4_loss: 0.9996 - head_0_acc: 0.6529 - head_1_acc: 0.6682 - head_2_acc: 0.6839 - head_3_acc: 0.6760 - head_4_acc: 0.6573 - val_loss: 5.5358 - val_head_0_loss: 1.2214 - val_head_1_loss: 1.1286 - val_head_2_loss: 1.0852 - val_head_3_loss: 1.0605 - val_head_4_loss: 1.0401 - val_head_0_acc: 0.6422 - val_head_1_acc: 0.6510 - val_head_2_acc: 0.6594 - val_head_3_acc: 0.6797 - val_head_4_acc: 0.6728\n",
      "Epoch 19/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 4.6579 - head_0_loss: 1.0087 - head_1_loss: 0.9151 - head_2_loss: 0.8853 - head_3_loss: 0.8983 - head_4_loss: 0.9505 - head_0_acc: 0.6690 - head_1_acc: 0.6899 - head_2_acc: 0.7007 - head_3_acc: 0.6938 - head_4_acc: 0.6758 - val_loss: 5.4293 - val_head_0_loss: 1.2042 - val_head_1_loss: 1.1064 - val_head_2_loss: 1.0599 - val_head_3_loss: 1.0293 - val_head_4_loss: 1.0294 - val_head_0_acc: 0.6382 - val_head_1_acc: 0.6579 - val_head_2_acc: 0.6737 - val_head_3_acc: 0.6900 - val_head_4_acc: 0.6718\n",
      "Epoch 20/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 4.4466 - head_0_loss: 0.9682 - head_1_loss: 0.8827 - head_2_loss: 0.8416 - head_3_loss: 0.8547 - head_4_loss: 0.8994 - head_0_acc: 0.6729 - head_1_acc: 0.7029 - head_2_acc: 0.7111 - head_3_acc: 0.7068 - head_4_acc: 0.6897 - val_loss: 5.3027 - val_head_0_loss: 1.1643 - val_head_1_loss: 1.0792 - val_head_2_loss: 1.0373 - val_head_3_loss: 1.0074 - val_head_4_loss: 1.0145 - val_head_0_acc: 0.6481 - val_head_1_acc: 0.6688 - val_head_2_acc: 0.6777 - val_head_3_acc: 0.6969 - val_head_4_acc: 0.6890\n",
      "Epoch 21/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 4.1770 - head_0_loss: 0.9154 - head_1_loss: 0.8171 - head_2_loss: 0.7954 - head_3_loss: 0.8045 - head_4_loss: 0.8446 - head_0_acc: 0.6936 - head_1_acc: 0.7218 - head_2_acc: 0.7235 - head_3_acc: 0.7210 - head_4_acc: 0.7139 - val_loss: 5.2944 - val_head_0_loss: 1.1653 - val_head_1_loss: 1.0645 - val_head_2_loss: 1.0419 - val_head_3_loss: 1.0081 - val_head_4_loss: 1.0146 - val_head_0_acc: 0.6609 - val_head_1_acc: 0.6856 - val_head_2_acc: 0.6871 - val_head_3_acc: 0.6979 - val_head_4_acc: 0.6881\n",
      "Epoch 22/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 3.9752 - head_0_loss: 0.8615 - head_1_loss: 0.7921 - head_2_loss: 0.7557 - head_3_loss: 0.7587 - head_4_loss: 0.8072 - head_0_acc: 0.7126 - head_1_acc: 0.7316 - head_2_acc: 0.7382 - head_3_acc: 0.7399 - head_4_acc: 0.7230 - val_loss: 5.3329 - val_head_0_loss: 1.1763 - val_head_1_loss: 1.0695 - val_head_2_loss: 1.0493 - val_head_3_loss: 1.0266 - val_head_4_loss: 1.0113 - val_head_0_acc: 0.6540 - val_head_1_acc: 0.6787 - val_head_2_acc: 0.6856 - val_head_3_acc: 0.6866 - val_head_4_acc: 0.6969\n",
      "Epoch 23/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 3.8407 - head_0_loss: 0.8343 - head_1_loss: 0.7664 - head_2_loss: 0.7243 - head_3_loss: 0.7373 - head_4_loss: 0.7784 - head_0_acc: 0.7180 - head_1_acc: 0.7397 - head_2_acc: 0.7493 - head_3_acc: 0.7422 - head_4_acc: 0.7335 - val_loss: 5.0646 - val_head_0_loss: 1.1098 - val_head_1_loss: 1.0358 - val_head_2_loss: 0.9889 - val_head_3_loss: 0.9699 - val_head_4_loss: 0.9602 - val_head_0_acc: 0.6846 - val_head_1_acc: 0.6964 - val_head_2_acc: 0.7063 - val_head_3_acc: 0.7187 - val_head_4_acc: 0.7014\n",
      "Epoch 24/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 3.6479 - head_0_loss: 0.7859 - head_1_loss: 0.7268 - head_2_loss: 0.6940 - head_3_loss: 0.7074 - head_4_loss: 0.7338 - head_0_acc: 0.7333 - head_1_acc: 0.7488 - head_2_acc: 0.7564 - head_3_acc: 0.7507 - head_4_acc: 0.7501 - val_loss: 5.0698 - val_head_0_loss: 1.1054 - val_head_1_loss: 1.0225 - val_head_2_loss: 0.9918 - val_head_3_loss: 0.9788 - val_head_4_loss: 0.9713 - val_head_0_acc: 0.6900 - val_head_1_acc: 0.6945 - val_head_2_acc: 0.7004 - val_head_3_acc: 0.7068 - val_head_4_acc: 0.7034\n",
      "Epoch 25/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 3.5096 - head_0_loss: 0.7555 - head_1_loss: 0.6926 - head_2_loss: 0.6592 - head_3_loss: 0.6765 - head_4_loss: 0.7259 - head_0_acc: 0.7444 - head_1_acc: 0.7624 - head_2_acc: 0.7710 - head_3_acc: 0.7653 - head_4_acc: 0.7463 - val_loss: 5.1444 - val_head_0_loss: 1.1408 - val_head_1_loss: 1.0358 - val_head_2_loss: 1.0039 - val_head_3_loss: 0.9991 - val_head_4_loss: 0.9648 - val_head_0_acc: 0.6816 - val_head_1_acc: 0.6979 - val_head_2_acc: 0.7073 - val_head_3_acc: 0.7122 - val_head_4_acc: 0.7137\n",
      "Epoch 26/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 3.3827 - head_0_loss: 0.7330 - head_1_loss: 0.6636 - head_2_loss: 0.6329 - head_3_loss: 0.6537 - head_4_loss: 0.6995 - head_0_acc: 0.7548 - head_1_acc: 0.7703 - head_2_acc: 0.7803 - head_3_acc: 0.7738 - head_4_acc: 0.7597 - val_loss: 5.0323 - val_head_0_loss: 1.1219 - val_head_1_loss: 1.0025 - val_head_2_loss: 0.9683 - val_head_3_loss: 0.9763 - val_head_4_loss: 0.9633 - val_head_0_acc: 0.6821 - val_head_1_acc: 0.6999 - val_head_2_acc: 0.7073 - val_head_3_acc: 0.7167 - val_head_4_acc: 0.7162\n",
      "Epoch 27/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 3.2023 - head_0_loss: 0.6971 - head_1_loss: 0.6326 - head_2_loss: 0.6042 - head_3_loss: 0.6170 - head_4_loss: 0.6514 - head_0_acc: 0.7625 - head_1_acc: 0.7829 - head_2_acc: 0.7873 - head_3_acc: 0.7845 - head_4_acc: 0.7751 - val_loss: 5.0443 - val_head_0_loss: 1.1176 - val_head_1_loss: 1.0107 - val_head_2_loss: 0.9864 - val_head_3_loss: 0.9736 - val_head_4_loss: 0.9559 - val_head_0_acc: 0.7014 - val_head_1_acc: 0.7167 - val_head_2_acc: 0.7211 - val_head_3_acc: 0.7172 - val_head_4_acc: 0.7147\n",
      "Epoch 28/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 3.1145 - head_0_loss: 0.6815 - head_1_loss: 0.6180 - head_2_loss: 0.5865 - head_3_loss: 0.5949 - head_4_loss: 0.6335 - head_0_acc: 0.7679 - head_1_acc: 0.7842 - head_2_acc: 0.7940 - head_3_acc: 0.7901 - head_4_acc: 0.7775 - val_loss: 5.0127 - val_head_0_loss: 1.1039 - val_head_1_loss: 1.0039 - val_head_2_loss: 0.9703 - val_head_3_loss: 0.9706 - val_head_4_loss: 0.9640 - val_head_0_acc: 0.6950 - val_head_1_acc: 0.7187 - val_head_2_acc: 0.7127 - val_head_3_acc: 0.7206 - val_head_4_acc: 0.7142\n",
      "Epoch 29/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18232/18232 [==============================] - 40s 2ms/step - loss: 2.9648 - head_0_loss: 0.6454 - head_1_loss: 0.5931 - head_2_loss: 0.5544 - head_3_loss: 0.5676 - head_4_loss: 0.6044 - head_0_acc: 0.7809 - head_1_acc: 0.7919 - head_2_acc: 0.8055 - head_3_acc: 0.8021 - head_4_acc: 0.7930 - val_loss: 4.9192 - val_head_0_loss: 1.0851 - val_head_1_loss: 0.9806 - val_head_2_loss: 0.9618 - val_head_3_loss: 0.9423 - val_head_4_loss: 0.9494 - val_head_0_acc: 0.7108 - val_head_1_acc: 0.7206 - val_head_2_acc: 0.7226 - val_head_3_acc: 0.7359 - val_head_4_acc: 0.7256\n",
      "Epoch 30/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 2.8651 - head_0_loss: 0.6264 - head_1_loss: 0.5618 - head_2_loss: 0.5396 - head_3_loss: 0.5511 - head_4_loss: 0.5862 - head_0_acc: 0.7882 - head_1_acc: 0.8071 - head_2_acc: 0.8137 - head_3_acc: 0.8058 - head_4_acc: 0.7949 - val_loss: 5.0137 - val_head_0_loss: 1.1006 - val_head_1_loss: 1.0013 - val_head_2_loss: 0.9823 - val_head_3_loss: 0.9725 - val_head_4_loss: 0.9571 - val_head_0_acc: 0.7078 - val_head_1_acc: 0.7275 - val_head_2_acc: 0.7231 - val_head_3_acc: 0.7266 - val_head_4_acc: 0.7172\n",
      "Epoch 31/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 2.7449 - head_0_loss: 0.5947 - head_1_loss: 0.5377 - head_2_loss: 0.5282 - head_3_loss: 0.5279 - head_4_loss: 0.5564 - head_0_acc: 0.7978 - head_1_acc: 0.8129 - head_2_acc: 0.8138 - head_3_acc: 0.8158 - head_4_acc: 0.8063 - val_loss: 4.9338 - val_head_0_loss: 1.0935 - val_head_1_loss: 0.9939 - val_head_2_loss: 0.9645 - val_head_3_loss: 0.9454 - val_head_4_loss: 0.9366 - val_head_0_acc: 0.7029 - val_head_1_acc: 0.7345 - val_head_2_acc: 0.7285 - val_head_3_acc: 0.7275 - val_head_4_acc: 0.7330\n",
      "Epoch 32/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 2.6402 - head_0_loss: 0.5697 - head_1_loss: 0.5236 - head_2_loss: 0.5051 - head_3_loss: 0.5140 - head_4_loss: 0.5278 - head_0_acc: 0.8060 - head_1_acc: 0.8181 - head_2_acc: 0.8250 - head_3_acc: 0.8220 - head_4_acc: 0.8161 - val_loss: 5.0461 - val_head_0_loss: 1.1111 - val_head_1_loss: 1.0141 - val_head_2_loss: 0.9958 - val_head_3_loss: 0.9672 - val_head_4_loss: 0.9579 - val_head_0_acc: 0.7053 - val_head_1_acc: 0.7275 - val_head_2_acc: 0.7340 - val_head_3_acc: 0.7345 - val_head_4_acc: 0.7315\n",
      "Epoch 33/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 2.5707 - head_0_loss: 0.5481 - head_1_loss: 0.5072 - head_2_loss: 0.5011 - head_3_loss: 0.4976 - head_4_loss: 0.5168 - head_0_acc: 0.8137 - head_1_acc: 0.8258 - head_2_acc: 0.8275 - head_3_acc: 0.8240 - head_4_acc: 0.8192 - val_loss: 4.9474 - val_head_0_loss: 1.0887 - val_head_1_loss: 0.9910 - val_head_2_loss: 0.9726 - val_head_3_loss: 0.9486 - val_head_4_loss: 0.9463 - val_head_0_acc: 0.7127 - val_head_1_acc: 0.7354 - val_head_2_acc: 0.7320 - val_head_3_acc: 0.7320 - val_head_4_acc: 0.7251\n",
      "Epoch 34/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 2.4213 - head_0_loss: 0.5216 - head_1_loss: 0.4810 - head_2_loss: 0.4521 - head_3_loss: 0.4728 - head_4_loss: 0.4938 - head_0_acc: 0.8170 - head_1_acc: 0.8330 - head_2_acc: 0.8407 - head_3_acc: 0.8329 - head_4_acc: 0.8276 - val_loss: 4.9410 - val_head_0_loss: 1.0880 - val_head_1_loss: 0.9938 - val_head_2_loss: 0.9576 - val_head_3_loss: 0.9616 - val_head_4_loss: 0.9400 - val_head_0_acc: 0.7216 - val_head_1_acc: 0.7315 - val_head_2_acc: 0.7295 - val_head_3_acc: 0.7468 - val_head_4_acc: 0.7379\n",
      "Epoch 35/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 2.3542 - head_0_loss: 0.5047 - head_1_loss: 0.4644 - head_2_loss: 0.4463 - head_3_loss: 0.4563 - head_4_loss: 0.4824 - head_0_acc: 0.8260 - head_1_acc: 0.8403 - head_2_acc: 0.8444 - head_3_acc: 0.8410 - head_4_acc: 0.8324 - val_loss: 4.9488 - val_head_0_loss: 1.0914 - val_head_1_loss: 0.9977 - val_head_2_loss: 0.9701 - val_head_3_loss: 0.9567 - val_head_4_loss: 0.9330 - val_head_0_acc: 0.7157 - val_head_1_acc: 0.7389 - val_head_2_acc: 0.7399 - val_head_3_acc: 0.7409 - val_head_4_acc: 0.7409\n",
      "Epoch 36/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 2.2474 - head_0_loss: 0.4770 - head_1_loss: 0.4438 - head_2_loss: 0.4238 - head_3_loss: 0.4373 - head_4_loss: 0.4654 - head_0_acc: 0.8346 - head_1_acc: 0.8449 - head_2_acc: 0.8499 - head_3_acc: 0.8417 - head_4_acc: 0.8381 - val_loss: 5.0536 - val_head_0_loss: 1.1117 - val_head_1_loss: 1.0214 - val_head_2_loss: 0.9871 - val_head_3_loss: 0.9660 - val_head_4_loss: 0.9674 - val_head_0_acc: 0.7187 - val_head_1_acc: 0.7349 - val_head_2_acc: 0.7384 - val_head_3_acc: 0.7537 - val_head_4_acc: 0.7517\n",
      "Epoch 37/80\n",
      "18232/18232 [==============================] - 40s 2ms/step - loss: 2.1860 - head_0_loss: 0.4801 - head_1_loss: 0.4408 - head_2_loss: 0.4067 - head_3_loss: 0.4152 - head_4_loss: 0.4432 - head_0_acc: 0.8353 - head_1_acc: 0.8474 - head_2_acc: 0.8589 - head_3_acc: 0.8560 - head_4_acc: 0.8432 - val_loss: 5.1605 - val_head_0_loss: 1.1181 - val_head_1_loss: 1.0323 - val_head_2_loss: 1.0081 - val_head_3_loss: 1.0096 - val_head_4_loss: 0.9924 - val_head_0_acc: 0.7236 - val_head_1_acc: 0.7280 - val_head_2_acc: 0.7414 - val_head_3_acc: 0.7389 - val_head_4_acc: 0.7374\n",
      "Epoch 38/80\n",
      " 4600/18232 [======>.......................] - ETA: 28s - loss: 2.0816 - head_0_loss: 0.4452 - head_1_loss: 0.4097 - head_2_loss: 0.3957 - head_3_loss: 0.4018 - head_4_loss: 0.4292 - head_0_acc: 0.8465 - head_1_acc: 0.8565 - head_2_acc: 0.8574 - head_3_acc: 0.8561 - head_4_acc: 0.8570"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-21830e625162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m           callbacks=[tb_callback])\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# eva_data = eva_metric.get_data()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "\n",
    "time_str = time.strftime(\"%Y_%m_%d_%H_%M\")\n",
    "log_dir = './s1p10_logs/' + time_str\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir=log_dir,  \n",
    "                                          batch_size=batch_size, \n",
    "                                          update_freq='epoch')\n",
    "\n",
    "# eva_metric = EVAMetrics()\n",
    "\n",
    "model.fit(x=X_train,\n",
    "          y=y_train,\n",
    "          epochs=40,\n",
    "          validation_data=(X_val, y_val),\n",
    "          class_weight=CLASSES_WEIGHT,\n",
    "          initial_epoch=0,\n",
    "          shuffle=True,\n",
    "          batch_size=batch_size,\n",
    "          callbacks=[tb_callback])\n",
    "\n",
    "# eva_data = eva_metric.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(log_dir + \"/s1p10_model_%s.json\" % time_str, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(log_dir + \"/s1p10_model_%s.h5\" % time_str)\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regress_json = regressor.to_json()\n",
    "# with open(\"./s1p10_model/s1p10_noLSTM_regressor_%s.json\" % time_str, \"w\") as json_file:\n",
    "#     json_file.write(regress_json)\n",
    "\n",
    "# save classifier\n",
    "# regressor.save_weights(log_dir + \"/regressor_%s.h5\" % time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019_05_30_21_41'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #TODO: save X_train, y_train\n",
    "# # np.save('./s1p10_data/CH2_training_X.npy', X_train)\n",
    "# # np.save('./s1p10_data/CH2_training_y.npy', y_train)\n",
    "\n",
    "# np.save('./s1p10_data/CH2_validation_X.npy', X_val)\n",
    "# np.save('./s1p10_data/CH2_validation_y.npy', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
