{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea code name: `S1P10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, LSTM, PReLU, Reshape, Dropout, Activation, BatchNormalization\n",
    "from keras.models import model_from_json, Model\n",
    "import keras\n",
    "\n",
    "from s1p10_model.resnet8_body import resnet8_body\n",
    "\n",
    "from s1p10_training_utils import save_lstm, DataGenerator\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weight of each angle class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./s1p10_data/s1p10_classes_weight.json', 'r') as fp:\n",
    "    classes_weight = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load bins edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_edge = np.load('./s1p10_data/s1p10_bins_edge.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (200, 200, 1)\n",
    "NUM_CLASSES = len(classes_weight)\n",
    "NUM_PREDICT = 5\n",
    "LSTM_NUM_HIDDEN_STATE = 64\n",
    "WEIGHT_REGU = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model acrchitect\n",
    "\n",
    "1 Image -> ResNet-8 -> LSTM_1 -> LSTM_2 (return state = True) (use this to sample prediction) -> Dense + Softmax \n",
    "-> 10 steering angle ID\n",
    "\n",
    "## 1.2 Create Encoder\n",
    "Encoder is body of ResNet-8 from `Drone-Net` since it's already trained to recognize road curve -> helpful spatial information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py:210: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv2D)                 (None, 100, 100, 32) 832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 49, 49, 32)   0           conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_a (BatchNormalization)     (None, 49, 49, 32)   128         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 49, 49, 32)   0           bn_1_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_a (Conv2D)               (None, 25, 25, 32)   9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_b (BatchNormalization)     (None, 25, 25, 32)   128         conv_1_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 25, 25, 32)   0           bn_1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_b (Conv2D)               (None, 25, 25, 32)   9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_c (Conv2D)               (None, 25, 25, 32)   1056        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 25, 32)   0           conv_1_b[0][0]                   \n",
      "                                                                 conv_1_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_a (BatchNormalization)     (None, 25, 25, 32)   128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 25, 25, 32)   0           bn_2_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_a (Conv2D)               (None, 13, 13, 64)   18496       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_b (BatchNormalization)     (None, 13, 13, 64)   256         conv_2_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 13, 13, 64)   0           bn_2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_b (Conv2D)               (None, 13, 13, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_c (Conv2D)               (None, 13, 13, 64)   2112        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 13, 13, 64)   0           conv_2_b[0][0]                   \n",
      "                                                                 conv_2_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_3_a (BatchNormalization)     (None, 13, 13, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 13, 13, 64)   0           bn_3_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_a (Conv2D)               (None, 7, 7, 128)    73856       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_3_b (BatchNormalization)     (None, 7, 7, 128)    512         conv_3_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 128)    0           bn_3_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_b (Conv2D)               (None, 7, 7, 128)    147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_c (Conv2D)               (None, 7, 7, 128)    8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 7, 7, 128)    0           conv_3_b[0][0]                   \n",
      "                                                                 conv_3_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6272)         0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 6272)         0           flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 309,088\n",
      "Trainable params: 0\n",
      "Non-trainable params: 309,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = resnet8_body(IMAGE_SHAPE)\n",
    "# load resnet8 weights\n",
    "encoder.load_weights(\"./s1p10_model/named_resnet8_best_weights.h5\", by_name=True)\n",
    "for l in encoder.layers:\n",
    "    l.trainable = False\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Create Decoder\n",
    "Decoder is comprised of 2 LSTM & 2 Dense layers, last Dense layer is activated by Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_cell = LSTM(LSTM_NUM_HIDDEN_STATE, \n",
    "                 return_state=True, \n",
    "                 kernel_regularizer=None,\n",
    "                 recurrent_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 dropout=0.0, \n",
    "                 recurrent_dropout=0.0)  # use to sample angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_classifier(input_shape, num_classes, weight_regu_param):\n",
    "    \"\"\"\n",
    "    Define classifier made of several Dense layers\n",
    "    \"\"\"\n",
    "    X_in = Input(shape=input_shape)\n",
    "    \n",
    "    # 1st layer\n",
    "    X = BatchNormalization()(X_in)\n",
    "    \n",
    "    X = Dense(128)(X)\n",
    "    \n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # 2nd layer\n",
    "    X = Dense(64)(X)\n",
    "    \n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # 3rd layer\n",
    "    X = Dense(num_classes)(X)\n",
    "    \n",
    "    X_out = Activation('softmax')(X)\n",
    "    \n",
    "    model = Model(inputs=[X_in], outputs=[X_out], name='classifier_body')\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = dense_classifier((LSTM_NUM_HIDDEN_STATE, ), NUM_CLASSES, weight_regu_param=WEIGHT_REGU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 114)               7410      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 114)               0         \n",
      "=================================================================\n",
      "Total params: 24,242\n",
      "Trainable params: 24,114\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s1p10_model(input_shape, encoder, LSTM_cell, classifier, lstm_num_hidden_state, num_classes, num_labels):\n",
    "    \"\"\"\n",
    "    Define see-1-predict-10 model\n",
    "    \n",
    "    Input:\n",
    "        input_shape (tuple): shape of input image inputted to encoder\n",
    "        encoder (keras.Model)\n",
    "        LSTM_cell (keras.layers)\n",
    "        classifier (keras.Model)\n",
    "        \n",
    "    Output:\n",
    "        keras.Model\n",
    "    \"\"\"\n",
    "    X_in = Input(shape=input_shape, name=\"image_in\")\n",
    "    \n",
    "    # extract feature vector\n",
    "    X_feature = encoder(X_in)\n",
    "    X_feature = Reshape((1, -1))(X_feature)  # shape = (None, 1, 6272)\n",
    "    \n",
    "    # Initialize input to LSTM\n",
    "    a0 = Input(shape=(LSTM_NUM_HIDDEN_STATE, ), name=\"a0\")\n",
    "    c0 = Input(shape=(LSTM_NUM_HIDDEN_STATE, ), name=\"c0\")\n",
    "    \n",
    "    # True label of previous prediction. This will be concatenated with X_feature to make X\n",
    "    y_init = [Input(shape=(num_classes, ), name=\"y_%d\" % i) for i in range(num_labels)]  \n",
    "    \n",
    "    a = a0\n",
    "    c = c0\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    for i in range(num_labels):\n",
    "        # concatenate y & X_feature\n",
    "        y = Reshape((1, -1))(y_init[i])\n",
    "        X = keras.layers.concatenate([X_feature, y], axis=-1)\n",
    "        \n",
    "        # propagate X through LSTM_cell\n",
    "        a, _, c = LSTM_cell(X, initial_state=[a, c])\n",
    "        \n",
    "        # propagate hidden state \"a\" through classifier to get steering angle\n",
    "        y = classifier(a)\n",
    "        \n",
    "        # store y\n",
    "        outputs.append(y)\n",
    "    \n",
    "    model = Model(inputs=[X_in, a0, c0] + y_init, outputs=outputs)\n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_in (InputLayer)           (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet8 (Model)                 (None, 6272)         309088      image_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y_0 (InputLayer)                (None, 114)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 6272)      0           resnet8[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 114)       0           y_0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "y_1 (InputLayer)                (None, 114)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 6386)      0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "a0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 114)       0           y_1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "y_2 (InputLayer)                (None, 114)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 64), (None,  1651456     concatenate_1[0][0]              \n",
      "                                                                 a0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[2][2]                     \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[3][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 6386)      0           reshape_1[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 114)       0           y_2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "y_3 (InputLayer)                (None, 114)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1, 6386)      0           reshape_1[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 114)       0           y_3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "y_4 (InputLayer)                (None, 114)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1, 6386)      0           reshape_1[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 114)       0           y_4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1, 6386)      0           reshape_1[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classifier_body (Model)         (None, 114)          24242       lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,984,786\n",
      "Trainable params: 1,675,570\n",
      "Non-trainable params: 309,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = s1p10_model(IMAGE_SHAPE, \n",
    "                    encoder, \n",
    "                    LSTM_cell, \n",
    "                    classifier, \n",
    "                    LSTM_NUM_HIDDEN_STATE, \n",
    "                    NUM_CLASSES, \n",
    "                    NUM_PREDICT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adadelta', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "gen_param = {'data_root_dir': \"/home/user/Bureau/Dataset/udacity/\", \n",
    "             'img_shape': IMAGE_SHAPE, \n",
    "             'num_class': NUM_CLASSES, \n",
    "             'num_prediction': NUM_PREDICT, \n",
    "             'bins_edge': bins_edge,\n",
    "             'batch_size': batch_size, \n",
    "             'shuffle': True, \n",
    "             'lstm_dim_hidden_states': LSTM_NUM_HIDDEN_STATE,\n",
    "             'flip_prob': 0.5}\n",
    "\n",
    "train_gen = DataGenerator(\"./s1p10_data/s1p10_CH2_002_output_training.csv\", **gen_param)\n",
    "val_gen = DataGenerator(\"./s1p10_data/s1p10_CH2_002_output_validation.csv\", **gen_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = time.strftime(\"%Y_%m_%d_%H_%M\")\n",
    "log_dir = './s1p10_logs/' + time_str\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir=log_dir,  \n",
    "                                          batch_size=batch_size, \n",
    "                                          update_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3067: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 8/37\n",
      "182/182 [==============================] - 144s 793ms/step - loss: 15.0557 - classifier_body_loss: 3.0048 - classifier_body_acc: 0.2199 - classifier_body_acc_1: 0.2201 - classifier_body_acc_2: 0.2177 - classifier_body_acc_3: 0.2164 - classifier_body_acc_4: 0.2199 - val_loss: 28.5934 - val_classifier_body_loss: 6.0274 - val_classifier_body_acc: 0.1767 - val_classifier_body_acc_1: 0.1736 - val_classifier_body_acc_2: 0.1720 - val_classifier_body_acc_3: 0.1720 - val_classifier_body_acc_4: 0.1720\n",
      "Epoch 9/37\n",
      "182/182 [==============================] - 142s 779ms/step - loss: 13.5607 - classifier_body_loss: 2.7059 - classifier_body_acc: 0.2440 - classifier_body_acc_1: 0.2489 - classifier_body_acc_2: 0.2480 - classifier_body_acc_3: 0.2460 - classifier_body_acc_4: 0.2431 - val_loss: 31.7953 - val_classifier_body_loss: 6.6873 - val_classifier_body_acc: 0.1130 - val_classifier_body_acc_1: 0.1155 - val_classifier_body_acc_2: 0.1193 - val_classifier_body_acc_3: 0.1194 - val_classifier_body_acc_4: 0.1202\n",
      "Epoch 10/37\n",
      "182/182 [==============================] - 142s 781ms/step - loss: 13.0069 - classifier_body_loss: 2.5948 - classifier_body_acc: 0.2565 - classifier_body_acc_1: 0.2597 - classifier_body_acc_2: 0.2648 - classifier_body_acc_3: 0.2587 - classifier_body_acc_4: 0.2596 - val_loss: 33.6888 - val_classifier_body_loss: 7.0724 - val_classifier_body_acc: 0.1448 - val_classifier_body_acc_1: 0.1447 - val_classifier_body_acc_2: 0.1446 - val_classifier_body_acc_3: 0.1445 - val_classifier_body_acc_4: 0.1469\n",
      "Epoch 11/37\n",
      "182/182 [==============================] - 142s 782ms/step - loss: 12.6616 - classifier_body_loss: 2.5230 - classifier_body_acc: 0.2603 - classifier_body_acc_1: 0.2664 - classifier_body_acc_2: 0.2716 - classifier_body_acc_3: 0.2740 - classifier_body_acc_4: 0.2691 - val_loss: 36.3785 - val_classifier_body_loss: 7.6452 - val_classifier_body_acc: 0.1169 - val_classifier_body_acc_1: 0.1196 - val_classifier_body_acc_2: 0.1188 - val_classifier_body_acc_3: 0.1177 - val_classifier_body_acc_4: 0.1170\n",
      "Epoch 12/37\n",
      "182/182 [==============================] - 142s 781ms/step - loss: 12.3060 - classifier_body_loss: 2.4531 - classifier_body_acc: 0.2744 - classifier_body_acc_1: 0.2816 - classifier_body_acc_2: 0.2857 - classifier_body_acc_3: 0.2848 - classifier_body_acc_4: 0.2848 - val_loss: 34.9992 - val_classifier_body_loss: 7.3331 - val_classifier_body_acc: 0.1266 - val_classifier_body_acc_1: 0.1268 - val_classifier_body_acc_2: 0.1263 - val_classifier_body_acc_3: 0.1268 - val_classifier_body_acc_4: 0.1290\n",
      "Epoch 13/37\n",
      "182/182 [==============================] - 142s 780ms/step - loss: 12.0786 - classifier_body_loss: 2.4118 - classifier_body_acc: 0.2849 - classifier_body_acc_1: 0.2913 - classifier_body_acc_2: 0.2971 - classifier_body_acc_3: 0.2932 - classifier_body_acc_4: 0.2885 - val_loss: 34.8698 - val_classifier_body_loss: 7.3247 - val_classifier_body_acc: 0.1165 - val_classifier_body_acc_1: 0.1180 - val_classifier_body_acc_2: 0.1180 - val_classifier_body_acc_3: 0.1201 - val_classifier_body_acc_4: 0.1217\n",
      "Epoch 14/37\n",
      "182/182 [==============================] - 142s 780ms/step - loss: 11.8011 - classifier_body_loss: 2.3571 - classifier_body_acc: 0.2922 - classifier_body_acc_1: 0.3015 - classifier_body_acc_2: 0.3035 - classifier_body_acc_3: 0.2996 - classifier_body_acc_4: 0.2955 - val_loss: 36.3461 - val_classifier_body_loss: 7.6112 - val_classifier_body_acc: 0.1141 - val_classifier_body_acc_1: 0.1165 - val_classifier_body_acc_2: 0.1149 - val_classifier_body_acc_3: 0.1148 - val_classifier_body_acc_4: 0.1164\n",
      "Epoch 15/37\n",
      "182/182 [==============================] - 142s 781ms/step - loss: 11.5345 - classifier_body_loss: 2.2948 - classifier_body_acc: 0.3051 - classifier_body_acc_1: 0.3121 - classifier_body_acc_2: 0.3162 - classifier_body_acc_3: 0.3114 - classifier_body_acc_4: 0.3132 - val_loss: 36.4275 - val_classifier_body_loss: 7.6404 - val_classifier_body_acc: 0.1134 - val_classifier_body_acc_1: 0.1159 - val_classifier_body_acc_2: 0.1180 - val_classifier_body_acc_3: 0.1201 - val_classifier_body_acc_4: 0.1187\n",
      "Epoch 16/37\n",
      "182/182 [==============================] - 142s 779ms/step - loss: 11.4398 - classifier_body_loss: 2.2809 - classifier_body_acc: 0.2992 - classifier_body_acc_1: 0.3087 - classifier_body_acc_2: 0.3165 - classifier_body_acc_3: 0.3149 - classifier_body_acc_4: 0.3135 - val_loss: 35.3894 - val_classifier_body_loss: 7.4466 - val_classifier_body_acc: 0.1230 - val_classifier_body_acc_1: 0.1248 - val_classifier_body_acc_2: 0.1235 - val_classifier_body_acc_3: 0.1260 - val_classifier_body_acc_4: 0.1257\n",
      "Epoch 17/37\n",
      "182/182 [==============================] - 142s 778ms/step - loss: 11.2667 - classifier_body_loss: 2.2462 - classifier_body_acc: 0.3103 - classifier_body_acc_1: 0.3213 - classifier_body_acc_2: 0.3284 - classifier_body_acc_3: 0.3269 - classifier_body_acc_4: 0.3245 - val_loss: 36.7257 - val_classifier_body_loss: 7.7022 - val_classifier_body_acc: 0.1035 - val_classifier_body_acc_1: 0.1115 - val_classifier_body_acc_2: 0.1106 - val_classifier_body_acc_3: 0.1108 - val_classifier_body_acc_4: 0.1102\n",
      "Epoch 18/37\n",
      "182/182 [==============================] - 142s 779ms/step - loss: 11.1302 - classifier_body_loss: 2.2182 - classifier_body_acc: 0.3159 - classifier_body_acc_1: 0.3285 - classifier_body_acc_2: 0.3357 - classifier_body_acc_3: 0.3348 - classifier_body_acc_4: 0.3316 - val_loss: 37.7923 - val_classifier_body_loss: 7.8585 - val_classifier_body_acc: 0.0961 - val_classifier_body_acc_1: 0.0998 - val_classifier_body_acc_2: 0.1000 - val_classifier_body_acc_3: 0.1028 - val_classifier_body_acc_4: 0.1039\n",
      "Epoch 19/37\n",
      "182/182 [==============================] - 142s 780ms/step - loss: 11.0116 - classifier_body_loss: 2.1929 - classifier_body_acc: 0.3171 - classifier_body_acc_1: 0.3348 - classifier_body_acc_2: 0.3394 - classifier_body_acc_3: 0.3379 - classifier_body_acc_4: 0.3340 - val_loss: 37.1520 - val_classifier_body_loss: 7.7258 - val_classifier_body_acc: 0.0938 - val_classifier_body_acc_1: 0.1045 - val_classifier_body_acc_2: 0.1095 - val_classifier_body_acc_3: 0.1116 - val_classifier_body_acc_4: 0.1109\n",
      "Epoch 20/37\n",
      "182/182 [==============================] - 142s 783ms/step - loss: 10.8581 - classifier_body_loss: 2.1616 - classifier_body_acc: 0.3244 - classifier_body_acc_1: 0.3397 - classifier_body_acc_2: 0.3466 - classifier_body_acc_3: 0.3429 - classifier_body_acc_4: 0.3385 - val_loss: 38.5920 - val_classifier_body_loss: 7.9762 - val_classifier_body_acc: 0.0716 - val_classifier_body_acc_1: 0.0782 - val_classifier_body_acc_2: 0.0818 - val_classifier_body_acc_3: 0.0837 - val_classifier_body_acc_4: 0.0842\n",
      "Epoch 21/37\n",
      "182/182 [==============================] - 143s 784ms/step - loss: 10.8043 - classifier_body_loss: 2.1502 - classifier_body_acc: 0.3277 - classifier_body_acc_1: 0.3434 - classifier_body_acc_2: 0.3521 - classifier_body_acc_3: 0.3465 - classifier_body_acc_4: 0.3407 - val_loss: 38.3966 - val_classifier_body_loss: 7.9127 - val_classifier_body_acc: 0.0900 - val_classifier_body_acc_1: 0.0952 - val_classifier_body_acc_2: 0.0966 - val_classifier_body_acc_3: 0.0968 - val_classifier_body_acc_4: 0.0971\n",
      "Epoch 22/37\n",
      " 23/182 [==>...........................] - ETA: 51s - loss: 10.6381 - classifier_body_loss: 2.1222 - classifier_body_acc: 0.3230 - classifier_body_acc_1: 0.3461 - classifier_body_acc_2: 0.3500 - classifier_body_acc_3: 0.3613 - classifier_body_acc_4: 0.3487"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bb8ef2cca778>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     callbacks=[tb_callback])\n\u001b[0m",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    class_weight=classes_weight,\n",
    "                    epochs=37,\n",
    "                    validation_data=val_gen,\n",
    "                    initial_epoch=7,\n",
    "                    callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save shared_lstm\n",
    "save_lstm(LSTM_cell, time_str, log_dir)\n",
    "\n",
    "# save classifier\n",
    "classifier.save_weights(log_dir + \"/classifier_%s.h5\" % time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
