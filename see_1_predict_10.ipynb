{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea code name: `S1P10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, LSTM, PReLU, Reshape, Dropout, Activation, BatchNormalization\n",
    "from keras.models import model_from_json, Model\n",
    "import keras.backend as K\n",
    "import keras\n",
    "\n",
    "from s1p10_model.resnet8_body import resnet8_body\n",
    "\n",
    "from s1p10_training_utils import gen_regressor_dataset\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (200, 200, 1)\n",
    "NUM_LABELS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model Acrchitect\n",
    "\n",
    "1 Image -> ResNet-8 -> Dense regressor -> 5 steering angles\n",
    "\n",
    "## 1.2 Create Encoder\n",
    "Encoder is body of ResNet-8 from `Drone-Net` since it's already trained to recognize road curve -> helpful spatial information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py:210: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv2D)                 (None, 100, 100, 32) 832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 49, 49, 32)   0           conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_a (BatchNormalization)     (None, 49, 49, 32)   128         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 49, 49, 32)   0           bn_1_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_a (Conv2D)               (None, 25, 25, 32)   9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_b (BatchNormalization)     (None, 25, 25, 32)   128         conv_1_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 25, 25, 32)   0           bn_1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_b (Conv2D)               (None, 25, 25, 32)   9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_c (Conv2D)               (None, 25, 25, 32)   1056        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 25, 32)   0           conv_1_b[0][0]                   \n",
      "                                                                 conv_1_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_a (BatchNormalization)     (None, 25, 25, 32)   128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 25, 25, 32)   0           bn_2_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_a (Conv2D)               (None, 13, 13, 64)   18496       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_b (BatchNormalization)     (None, 13, 13, 64)   256         conv_2_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 13, 13, 64)   0           bn_2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_b (Conv2D)               (None, 13, 13, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_c (Conv2D)               (None, 13, 13, 64)   2112        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 13, 13, 64)   0           conv_2_b[0][0]                   \n",
      "                                                                 conv_2_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_3_a (BatchNormalization)     (None, 13, 13, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 13, 13, 64)   0           bn_3_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_a (Conv2D)               (None, 7, 7, 128)    73856       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_3_b (BatchNormalization)     (None, 7, 7, 128)    512         conv_3_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 128)    0           bn_3_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_b (Conv2D)               (None, 7, 7, 128)    147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_c (Conv2D)               (None, 7, 7, 128)    8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 7, 7, 128)    0           conv_3_b[0][0]                   \n",
      "                                                                 conv_3_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6272)         0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 6272)         0           flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 309,088\n",
      "Trainable params: 0\n",
      "Non-trainable params: 309,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = resnet8_body(IMAGE_SHAPE)\n",
    "# load resnet8 weights\n",
    "encoder.load_weights(\"./s1p10_model/named_resnet8_best_weights.h5\", by_name=True)\n",
    "for l in encoder.layers:\n",
    "    l.trainable = False\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Create Decoder\n",
    "Decoder is a seri of Dense layers with a non-activate Dense layer at the end to perform regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_regressor(input_shape, num_labels):\n",
    "    \"\"\"\n",
    "    Define classifier made of several Dense layers\n",
    "    \"\"\"\n",
    "    X_in = Input(shape=input_shape)\n",
    "    \n",
    "    # 1st layer\n",
    "    X = Dense(1200)(X_in)\n",
    "    \n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # 2nd layer\n",
    "    X = Dense(600)(X)\n",
    "    \n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # 3rd layer\n",
    "    X = Dense(200)(X)\n",
    "    \n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # 4th layer\n",
    "    y = Dense(num_labels, activation=None)(X)\n",
    "    \n",
    "    model = Model(inputs=[X_in], outputs=[y], name='regressor')\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1200)              7527600   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 600)               720600    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               120200    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 8,369,405\n",
      "Trainable params: 8,369,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressor = dense_regressor((6272, ), NUM_LABELS)\n",
    "\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s1p10_model(input_shape):\n",
    "    \"\"\"\n",
    "    Define see-1-predict-10 model\n",
    "    \n",
    "    Input:\n",
    "        input_shape (tuple): shape of input image inputted to encoder\n",
    "        \n",
    "    Output:\n",
    "        keras.Model\n",
    "    \"\"\"\n",
    "    X_in = Input(shape=input_shape, name=\"image_in\")\n",
    "    \n",
    "    # extract feature vector\n",
    "    X_feature = encoder(X_in)\n",
    "    \n",
    "    # apply regressor\n",
    "    y = regressor(X_feature)\n",
    "    \n",
    "    model = Model(inputs=[X_in], outputs=[y])\n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_in (InputLayer)        (None, 200, 200, 1)       0         \n",
      "_________________________________________________________________\n",
      "resnet8 (Model)              (None, 6272)              309088    \n",
      "_________________________________________________________________\n",
      "regressor (Model)            (None, 5)                 8369405   \n",
      "=================================================================\n",
      "Total params: 8,678,493\n",
      "Trainable params: 8,369,405\n",
      "Non-trainable params: 309,088\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = s1p10_model(IMAGE_SHAPE)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='mse', metrics=[root_mean_squared_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EVAMetrics(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self._data = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        X_val, y_val = self.validation_data[0], self.validation_data[1]\n",
    "        y_predict = np.asarray(self.model.predict(X_val))\n",
    "\n",
    "        exp_var = sklearn.metrics.explained_variance_score(y_val, y_predict, multioutput='uniform_average')\n",
    "        \n",
    "        self._data.append({\n",
    "            'EVA': exp_var,\n",
    "        })\n",
    "        return\n",
    "\n",
    "    def get_data(self):\n",
    "        return self._data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_param = {'num_labels': NUM_LABELS, \n",
    "             'image_shape': IMAGE_SHAPE, \n",
    "             'num_samples': None, \n",
    "             'data_root_dir': \"/home/user/Bureau/Dataset/udacity/\", \n",
    "             'flip_prob': 0.5}\n",
    "\n",
    "# X_train, y_train = gen_regressor_dataset(\"./s1p10_data/s1p10_CH2_002_output_training.csv\", **gen_param)\n",
    "X_train = np.load('./s1p10_data/CH2_training_X.npy')\n",
    "y_train = np.load('./s1p10_data/CH2_training_y.npy')\n",
    "# X_val, y_val = gen_regressor_dataset(\"./s1p10_data/s1p10_CH2_002_output_validation.csv\", **gen_param)\n",
    "X_val = np.load('./s1p10_data/CH2_validation_X.npy')\n",
    "y_val = np.load('./s1p10_data/CH2_validation_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3067: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 18232 samples, validate on 2026 samples\n",
      "Epoch 1/10\n",
      "18232/18232 [==============================] - 25s 1ms/step - loss: 17.8083 - root_mean_squared_error: 2.2277 - val_loss: 0.0813 - val_root_mean_squared_error: 0.2809\n",
      "Epoch 2/10\n",
      "18232/18232 [==============================] - 23s 1ms/step - loss: 0.2341 - root_mean_squared_error: 0.4760 - val_loss: 0.0812 - val_root_mean_squared_error: 0.2807\n",
      "Epoch 3/10\n",
      "18232/18232 [==============================] - 24s 1ms/step - loss: 0.1319 - root_mean_squared_error: 0.3582 - val_loss: 0.0812 - val_root_mean_squared_error: 0.2807\n",
      "Epoch 4/10\n",
      "18232/18232 [==============================] - 23s 1ms/step - loss: 0.1004 - root_mean_squared_error: 0.3140 - val_loss: 0.0812 - val_root_mean_squared_error: 0.2807\n",
      "Epoch 5/10\n",
      "18232/18232 [==============================] - 24s 1ms/step - loss: 0.0915 - root_mean_squared_error: 0.2989 - val_loss: 0.0812 - val_root_mean_squared_error: 0.2807\n",
      "Epoch 6/10\n",
      "18232/18232 [==============================] - 24s 1ms/step - loss: 0.0855 - root_mean_squared_error: 0.2886 - val_loss: 0.0812 - val_root_mean_squared_error: 0.2807\n",
      "Epoch 7/10\n",
      "18232/18232 [==============================] - 23s 1ms/step - loss: 0.0824 - root_mean_squared_error: 0.2831 - val_loss: 0.0812 - val_root_mean_squared_error: 0.2807\n",
      "Epoch 8/10\n",
      "18232/18232 [==============================] - 23s 1ms/step - loss: 0.0815 - root_mean_squared_error: 0.2819 - val_loss: 0.0812 - val_root_mean_squared_error: 0.2807\n",
      "Epoch 9/10\n",
      "18232/18232 [==============================] - 24s 1ms/step - loss: 0.0797 - root_mean_squared_error: 0.2784 - val_loss: 0.0812 - val_root_mean_squared_error: 0.2807\n",
      "Epoch 10/10\n",
      "18232/18232 [==============================] - 24s 1ms/step - loss: 0.0781 - root_mean_squared_error: 0.2757 - val_loss: 0.0812 - val_root_mean_squared_error: 0.2807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'EVA': -0.0014462419000519145},\n",
       " {'EVA': -3.438529685351188e-05},\n",
       " {'EVA': -1.7422276687995008e-08},\n",
       " {'EVA': -4.4408920985006264e-17},\n",
       " {'EVA': 0.0},\n",
       " {'EVA': 0.0},\n",
       " {'EVA': 0.0},\n",
       " {'EVA': -4.4408920985006264e-17},\n",
       " {'EVA': -4.4408920985006264e-17},\n",
       " {'EVA': 0.0}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "time_str = time.strftime(\"%Y_%m_%d_%H_%M\")\n",
    "log_dir = './s1p10_logs/' + time_str\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir=log_dir,  \n",
    "                                          batch_size=batch_size, \n",
    "                                          update_freq='epoch')\n",
    "\n",
    "eva_metric = EVAMetrics()\n",
    "model.fit(x=X_train,\n",
    "          y=y_train,\n",
    "          epochs=10,\n",
    "          validation_data=(X_val, y_val),\n",
    "          initial_epoch=0,\n",
    "          shuffle=True,\n",
    "          batch_size=batch_size,\n",
    "          callbacks=[tb_callback, eva_metric])\n",
    "eva_metric.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save classifier\n",
    "regressor.save_weights(log_dir + \"/regressor_%s.h5\" % time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019_05_29_16_20'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO: save X_train, y_train\n",
    "# np.save('./s1p10_data/CH2_training_X.npy', X_train)\n",
    "# np.save('./s1p10_data/CH2_training_y.npy', y_train)\n",
    "\n",
    "# np.save('./s1p10_data/CH2_validation_X.npy', X_val)\n",
    "# np.save('./s1p10_data/CH2_validation_y.npy', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
