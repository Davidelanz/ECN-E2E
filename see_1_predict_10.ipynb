{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea code name: `S1P10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, LSTM, PReLU, Reshape, Dropout\n",
    "from keras.models import model_from_json, Model\n",
    "import keras\n",
    "\n",
    "from s1p10_model.resnet8_body import resnet8_body\n",
    "\n",
    "from s1p10_training_utils import save_lstm, DataGenerator\n",
    "\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weight of each angle class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./s1p10_data/s1p10_classes_weight.json', 'r') as fp:\n",
    "    classes_weight = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (200, 200, 1)\n",
    "NUM_CLASSES = len(classes_weight)\n",
    "NUM_PREDICT = 5\n",
    "LSTM_NUM_HIDDEN_STATE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model acrchitect\n",
    "\n",
    "1 Image -> ResNet-8 -> LSTM_1 -> LSTM_2 (return state = True) (use this to sample prediction) -> Dense + Softmax \n",
    "-> 10 steering angle ID\n",
    "\n",
    "## 1.2 Create Encoder\n",
    "Encoder is body of ResNet-8 from `Drone-Net` since it's already trained to recognize road curve -> helpful spatial information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py:210: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv2D)                 (None, 100, 100, 32) 832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 49, 49, 32)   0           conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_a (BatchNormalization)     (None, 49, 49, 32)   128         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 49, 49, 32)   0           bn_1_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_a (Conv2D)               (None, 25, 25, 32)   9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_b (BatchNormalization)     (None, 25, 25, 32)   128         conv_1_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 25, 25, 32)   0           bn_1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_b (Conv2D)               (None, 25, 25, 32)   9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_c (Conv2D)               (None, 25, 25, 32)   1056        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 25, 32)   0           conv_1_b[0][0]                   \n",
      "                                                                 conv_1_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_a (BatchNormalization)     (None, 25, 25, 32)   128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 25, 25, 32)   0           bn_2_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_a (Conv2D)               (None, 13, 13, 64)   18496       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_b (BatchNormalization)     (None, 13, 13, 64)   256         conv_2_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 13, 13, 64)   0           bn_2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_b (Conv2D)               (None, 13, 13, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_c (Conv2D)               (None, 13, 13, 64)   2112        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 13, 13, 64)   0           conv_2_b[0][0]                   \n",
      "                                                                 conv_2_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_3_a (BatchNormalization)     (None, 13, 13, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 13, 13, 64)   0           bn_3_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_a (Conv2D)               (None, 7, 7, 128)    73856       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_3_b (BatchNormalization)     (None, 7, 7, 128)    512         conv_3_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 128)    0           bn_3_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_b (Conv2D)               (None, 7, 7, 128)    147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_c (Conv2D)               (None, 7, 7, 128)    8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 7, 7, 128)    0           conv_3_b[0][0]                   \n",
      "                                                                 conv_3_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6272)         0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 6272)         0           flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 309,088\n",
      "Trainable params: 0\n",
      "Non-trainable params: 309,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = resnet8_body(IMAGE_SHAPE)\n",
    "# load resnet8 weights\n",
    "encoder.load_weights(\"./s1p10_model/named_resnet8_best_weights.h5\", by_name=True)\n",
    "for l in encoder.layers:\n",
    "    l.trainable = False\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Create Decoder\n",
    "Decoder is comprised of 2 LSTM & 2 Dense layers, last Dense layer is activated by Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_cell = LSTM(LSTM_NUM_HIDDEN_STATE, return_state=True)  # use to sample angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_classifier(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Define classifier made of several Dense layers\n",
    "    \"\"\"\n",
    "    X_in = Input(shape=input_shape)\n",
    "    \n",
    "    X = Dense(128)(X_in)\n",
    "    \n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    X = PReLU()(X)  # use PReLU activation\n",
    "    \n",
    "    X = Dense(64)(X)\n",
    "    \n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    X = PReLU()(X)\n",
    "    \n",
    "    y = Dense(num_classes, activation='softmax')(X)\n",
    "    \n",
    "    model = Model(inputs=[X_in], outputs=[y], name='classifier')\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "classifier = dense_classifier((LSTM_NUM_HIDDEN_STATE, ), NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 128)               128       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 64)                64        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 114)               7410      \n",
      "=================================================================\n",
      "Total params: 32,370\n",
      "Trainable params: 32,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s1p10_model(input_shape, encoder, LSTM_cell, classifier, lstm_num_hidden_state, num_classes, num_labels):\n",
    "    \"\"\"\n",
    "    Define see-1-predict-10 model\n",
    "    \n",
    "    Input:\n",
    "        input_shape (tuple): shape of input image inputted to encoder\n",
    "        encoder (keras.Model)\n",
    "        LSTM_cell (keras.layers)\n",
    "        classifier (keras.Model)\n",
    "        \n",
    "    Output:\n",
    "        keras.Model\n",
    "    \"\"\"\n",
    "    X_in = Input(shape=input_shape, name=\"image_in\")\n",
    "    \n",
    "    # extract feature vector\n",
    "    X_feature = encoder(X_in)\n",
    "    X_feature = Reshape((1, -1))(X_feature)  # shape = (None, 1, 6272)\n",
    "    \n",
    "    # Initialize input to LSTM\n",
    "    a0 = Input(shape=(LSTM_NUM_HIDDEN_STATE, ), name=\"a0\")\n",
    "    c0 = Input(shape=(LSTM_NUM_HIDDEN_STATE, ), name=\"c0\")\n",
    "    y0 = Input(shape=(num_classes, ), name=\"y0\")  # will be concatenated with X_feature to make X\n",
    "    \n",
    "    a = a0\n",
    "    c = c0\n",
    "    y = y0\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    for i in range(num_labels):\n",
    "        # concatenate y & X_feature\n",
    "        y = Reshape((1, -1))(y)\n",
    "        X = keras.layers.concatenate([X_feature, y], axis=-1)\n",
    "        # propagate X through LSTM_cell\n",
    "        a, _, c = LSTM_cell(X, initial_state=[a, c])\n",
    "        # propagate hidden state \"a\" through classifier to get steering angle\n",
    "        y = classifier(a)\n",
    "        # store y\n",
    "        outputs.append(y)\n",
    "    \n",
    "    model = Model(inputs=[X_in, a0, c0, y0], outputs=outputs)\n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_in (InputLayer)           (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet8 (Model)                 (None, 6272)         309088      image_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y0 (InputLayer)                 (None, 114)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 6272)      0           resnet8[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 114)       0           y0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 6386)      0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "a0 (InputLayer)                 (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 128), (None, 3335680     concatenate_1[0][0]              \n",
      "                                                                 a0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[2][2]                     \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[3][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "classifier (Model)              (None, 114)          32370       lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 114)       0           classifier[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 6386)      0           reshape_1[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 114)       0           classifier[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1, 6386)      0           reshape_1[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 114)       0           classifier[3][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1, 6386)      0           reshape_1[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 114)       0           classifier[4][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1, 6386)      0           reshape_1[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,677,138\n",
      "Trainable params: 3,368,050\n",
      "Non-trainable params: 309,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = s1p10_model(IMAGE_SHAPE, \n",
    "                    encoder, \n",
    "                    LSTM_cell, \n",
    "                    classifier, \n",
    "                    LSTM_NUM_HIDDEN_STATE, \n",
    "                    NUM_CLASSES, \n",
    "                    NUM_PREDICT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adadelta', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "gen_param = {'data_root_dir': \"/home/user/Bureau/Dataset/udacity/\", \n",
    "             'img_shape': IMAGE_SHAPE, \n",
    "             'num_class': NUM_CLASSES, \n",
    "             'num_prediction': NUM_PREDICT, \n",
    "             'batch_size': batch_size, \n",
    "             'shuffle': True, \n",
    "             'lstm_dim_hidden_states': LSTM_NUM_HIDDEN_STATE}\n",
    "\n",
    "train_gen = DataGenerator(\"./s1p10_data/s1p10_CH2_002_output_training.csv\", **gen_param)\n",
    "val_gen = DataGenerator(\"./s1p10_data/s1p10_CH2_002_output_validation.csv\", **gen_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = time.strftime(\"%Y_%m_%d_%H_%M\")\n",
    "log_dir = './s1p10_logs/' + time_str\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir=log_dir,  \n",
    "                                          batch_size=batch_size, \n",
    "                                          update_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3067: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "284/284 [==============================] - 111s 392ms/step - loss: 15.3273 - classifier_loss: 3.0582 - classifier_acc: 0.2197 - classifier_acc_1: 0.2172 - classifier_acc_2: 0.2179 - classifier_acc_3: 0.2159 - classifier_acc_4: 0.2199 - val_loss: 16.7937 - val_classifier_loss: 3.3248 - val_classifier_acc: 0.2116 - val_classifier_acc_1: 0.2117 - val_classifier_acc_2: 0.2082 - val_classifier_acc_3: 0.2074 - val_classifier_acc_4: 0.2086\n",
      "Epoch 2/20\n",
      "284/284 [==============================] - 103s 364ms/step - loss: 13.4305 - classifier_loss: 2.6762 - classifier_acc: 0.2524 - classifier_acc_1: 0.2512 - classifier_acc_2: 0.2538 - classifier_acc_3: 0.2503 - classifier_acc_4: 0.2545 - val_loss: 17.2256 - val_classifier_loss: 3.4434 - val_classifier_acc: 0.1765 - val_classifier_acc_1: 0.1715 - val_classifier_acc_2: 0.1682 - val_classifier_acc_3: 0.1692 - val_classifier_acc_4: 0.1691\n",
      "Epoch 3/20\n",
      "284/284 [==============================] - 105s 369ms/step - loss: 12.6477 - classifier_loss: 2.5200 - classifier_acc: 0.2679 - classifier_acc_1: 0.2715 - classifier_acc_2: 0.2734 - classifier_acc_3: 0.2720 - classifier_acc_4: 0.2739 - val_loss: 18.5717 - val_classifier_loss: 3.7351 - val_classifier_acc: 0.1260 - val_classifier_acc_1: 0.1254 - val_classifier_acc_2: 0.1232 - val_classifier_acc_3: 0.1231 - val_classifier_acc_4: 0.1199\n",
      "Epoch 4/20\n",
      "284/284 [==============================] - 104s 367ms/step - loss: 12.0386 - classifier_loss: 2.3959 - classifier_acc: 0.2841 - classifier_acc_1: 0.2901 - classifier_acc_2: 0.2897 - classifier_acc_3: 0.2892 - classifier_acc_4: 0.2945 - val_loss: 20.1106 - val_classifier_loss: 4.0814 - val_classifier_acc: 0.1103 - val_classifier_acc_1: 0.1079 - val_classifier_acc_2: 0.1043 - val_classifier_acc_3: 0.1012 - val_classifier_acc_4: 0.1019\n",
      "Epoch 5/20\n",
      "284/284 [==============================] - 104s 365ms/step - loss: 11.7141 - classifier_loss: 2.3268 - classifier_acc: 0.2947 - classifier_acc_1: 0.3031 - classifier_acc_2: 0.3041 - classifier_acc_3: 0.3028 - classifier_acc_4: 0.3000 - val_loss: 21.2241 - val_classifier_loss: 4.3262 - val_classifier_acc: 0.0975 - val_classifier_acc_1: 0.0927 - val_classifier_acc_2: 0.0891 - val_classifier_acc_3: 0.0887 - val_classifier_acc_4: 0.0882\n",
      "Epoch 6/20\n",
      "284/284 [==============================] - 104s 367ms/step - loss: 11.2441 - classifier_loss: 2.2359 - classifier_acc: 0.3055 - classifier_acc_1: 0.3131 - classifier_acc_2: 0.3146 - classifier_acc_3: 0.3135 - classifier_acc_4: 0.3124 - val_loss: 23.6042 - val_classifier_loss: 4.8552 - val_classifier_acc: 0.0773 - val_classifier_acc_1: 0.0742 - val_classifier_acc_2: 0.0708 - val_classifier_acc_3: 0.0718 - val_classifier_acc_4: 0.0703\n",
      "Epoch 7/20\n",
      "284/284 [==============================] - 104s 365ms/step - loss: 10.9201 - classifier_loss: 2.1754 - classifier_acc: 0.3148 - classifier_acc_1: 0.3212 - classifier_acc_2: 0.3288 - classifier_acc_3: 0.3258 - classifier_acc_4: 0.3250 - val_loss: 24.2153 - val_classifier_loss: 4.9973 - val_classifier_acc: 0.0783 - val_classifier_acc_1: 0.0764 - val_classifier_acc_2: 0.0721 - val_classifier_acc_3: 0.0730 - val_classifier_acc_4: 0.0722\n",
      "Epoch 8/20\n",
      "284/284 [==============================] - 104s 366ms/step - loss: 10.6976 - classifier_loss: 2.1382 - classifier_acc: 0.3259 - classifier_acc_1: 0.3394 - classifier_acc_2: 0.3375 - classifier_acc_3: 0.3350 - classifier_acc_4: 0.3299 - val_loss: 24.9582 - val_classifier_loss: 5.1557 - val_classifier_acc: 0.0681 - val_classifier_acc_1: 0.0665 - val_classifier_acc_2: 0.0633 - val_classifier_acc_3: 0.0626 - val_classifier_acc_4: 0.0641\n",
      "Epoch 9/20\n",
      "284/284 [==============================] - 105s 369ms/step - loss: 10.4941 - classifier_loss: 2.1030 - classifier_acc: 0.3294 - classifier_acc_1: 0.3393 - classifier_acc_2: 0.3486 - classifier_acc_3: 0.3431 - classifier_acc_4: 0.3409 - val_loss: 25.2132 - val_classifier_loss: 5.2178 - val_classifier_acc: 0.0700 - val_classifier_acc_1: 0.0679 - val_classifier_acc_2: 0.0667 - val_classifier_acc_3: 0.0687 - val_classifier_acc_4: 0.0670\n",
      "Epoch 10/20\n",
      "284/284 [==============================] - 104s 366ms/step - loss: 10.3491 - classifier_loss: 2.0725 - classifier_acc: 0.3378 - classifier_acc_1: 0.3517 - classifier_acc_2: 0.3567 - classifier_acc_3: 0.3532 - classifier_acc_4: 0.3477 - val_loss: 25.6014 - val_classifier_loss: 5.3144 - val_classifier_acc: 0.0758 - val_classifier_acc_1: 0.0723 - val_classifier_acc_2: 0.0697 - val_classifier_acc_3: 0.0706 - val_classifier_acc_4: 0.0684\n",
      "Epoch 11/20\n",
      "284/284 [==============================] - 104s 368ms/step - loss: 10.1099 - classifier_loss: 2.0280 - classifier_acc: 0.3467 - classifier_acc_1: 0.3602 - classifier_acc_2: 0.3664 - classifier_acc_3: 0.3623 - classifier_acc_4: 0.3550 - val_loss: 26.4930 - val_classifier_loss: 5.5147 - val_classifier_acc: 0.0727 - val_classifier_acc_1: 0.0704 - val_classifier_acc_2: 0.0684 - val_classifier_acc_3: 0.0698 - val_classifier_acc_4: 0.0688\n",
      "Epoch 12/20\n",
      "284/284 [==============================] - 104s 366ms/step - loss: 9.9523 - classifier_loss: 1.9950 - classifier_acc: 0.3507 - classifier_acc_1: 0.3681 - classifier_acc_2: 0.3730 - classifier_acc_3: 0.3697 - classifier_acc_4: 0.3604 - val_loss: 26.7279 - val_classifier_loss: 5.5730 - val_classifier_acc: 0.0763 - val_classifier_acc_1: 0.0709 - val_classifier_acc_2: 0.0678 - val_classifier_acc_3: 0.0700 - val_classifier_acc_4: 0.0679\n",
      "Epoch 13/20\n",
      "284/284 [==============================] - 104s 366ms/step - loss: 9.8163 - classifier_loss: 1.9734 - classifier_acc: 0.3591 - classifier_acc_1: 0.3790 - classifier_acc_2: 0.3866 - classifier_acc_3: 0.3802 - classifier_acc_4: 0.3715 - val_loss: 27.6135 - val_classifier_loss: 5.7603 - val_classifier_acc: 0.0734 - val_classifier_acc_1: 0.0666 - val_classifier_acc_2: 0.0639 - val_classifier_acc_3: 0.0654 - val_classifier_acc_4: 0.0660\n",
      "Epoch 14/20\n",
      "284/284 [==============================] - 105s 368ms/step - loss: 9.6907 - classifier_loss: 1.9494 - classifier_acc: 0.3621 - classifier_acc_1: 0.3841 - classifier_acc_2: 0.3899 - classifier_acc_3: 0.3847 - classifier_acc_4: 0.3732 - val_loss: 27.5556 - val_classifier_loss: 5.7446 - val_classifier_acc: 0.0739 - val_classifier_acc_1: 0.0692 - val_classifier_acc_2: 0.0650 - val_classifier_acc_3: 0.0646 - val_classifier_acc_4: 0.0644\n",
      "Epoch 15/20\n",
      "284/284 [==============================] - 104s 365ms/step - loss: 9.5910 - classifier_loss: 1.9391 - classifier_acc: 0.3650 - classifier_acc_1: 0.3863 - classifier_acc_2: 0.3988 - classifier_acc_3: 0.3884 - classifier_acc_4: 0.3774 - val_loss: 29.5179 - val_classifier_loss: 6.1692 - val_classifier_acc: 0.0657 - val_classifier_acc_1: 0.0634 - val_classifier_acc_2: 0.0618 - val_classifier_acc_3: 0.0608 - val_classifier_acc_4: 0.0610\n",
      "Epoch 16/20\n",
      "284/284 [==============================] - 105s 371ms/step - loss: 9.5701 - classifier_loss: 1.9317 - classifier_acc: 0.3683 - classifier_acc_1: 0.3892 - classifier_acc_2: 0.3926 - classifier_acc_3: 0.3907 - classifier_acc_4: 0.3784 - val_loss: 29.5188 - val_classifier_loss: 6.1625 - val_classifier_acc: 0.0630 - val_classifier_acc_1: 0.0585 - val_classifier_acc_2: 0.0594 - val_classifier_acc_3: 0.0589 - val_classifier_acc_4: 0.0574\n",
      "Epoch 17/20\n",
      "284/284 [==============================] - 105s 369ms/step - loss: 9.4004 - classifier_loss: 1.9010 - classifier_acc: 0.3759 - classifier_acc_1: 0.3968 - classifier_acc_2: 0.4018 - classifier_acc_3: 0.3994 - classifier_acc_4: 0.3855 - val_loss: 30.0786 - val_classifier_loss: 6.2581 - val_classifier_acc: 0.0563 - val_classifier_acc_1: 0.0524 - val_classifier_acc_2: 0.0549 - val_classifier_acc_3: 0.0555 - val_classifier_acc_4: 0.0565\n",
      "Epoch 18/20\n",
      "284/284 [==============================] - 105s 370ms/step - loss: 9.2782 - classifier_loss: 1.8809 - classifier_acc: 0.3801 - classifier_acc_1: 0.4025 - classifier_acc_2: 0.4077 - classifier_acc_3: 0.4060 - classifier_acc_4: 0.3896 - val_loss: 30.9932 - val_classifier_loss: 6.4539 - val_classifier_acc: 0.0525 - val_classifier_acc_1: 0.0529 - val_classifier_acc_2: 0.0541 - val_classifier_acc_3: 0.0560 - val_classifier_acc_4: 0.0552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "284/284 [==============================] - 105s 370ms/step - loss: 9.1746 - classifier_loss: 1.8519 - classifier_acc: 0.3806 - classifier_acc_1: 0.4025 - classifier_acc_2: 0.4130 - classifier_acc_3: 0.4067 - classifier_acc_4: 0.3923 - val_loss: 31.5336 - val_classifier_loss: 6.5638 - val_classifier_acc: 0.0519 - val_classifier_acc_1: 0.0538 - val_classifier_acc_2: 0.0559 - val_classifier_acc_3: 0.0574 - val_classifier_acc_4: 0.0583\n",
      "Epoch 20/20\n",
      "284/284 [==============================] - 104s 367ms/step - loss: 9.0056 - classifier_loss: 1.8258 - classifier_acc: 0.3872 - classifier_acc_1: 0.4121 - classifier_acc_2: 0.4245 - classifier_acc_3: 0.4202 - classifier_acc_4: 0.4020 - val_loss: 33.3867 - val_classifier_loss: 6.9565 - val_classifier_acc: 0.0547 - val_classifier_acc_1: 0.0532 - val_classifier_acc_2: 0.0546 - val_classifier_acc_3: 0.0546 - val_classifier_acc_4: 0.0559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4e61807c88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    class_weight=classes_weight,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_gen,\n",
    "                    initial_epoch=0,\n",
    "                    callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save shared_lstm\n",
    "save_lstm(LSTM_cell, time_str, log_dir)\n",
    "\n",
    "# save classifier\n",
    "classifier.save_weights(log_dir + \"/classifier_%s.h5\" % time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019_05_27_08_54'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
