{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.merge import add\n",
    "from keras import regularizers\n",
    "import keras\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition\n",
    "\n",
    "## Encoder\n",
    "The role of this model is to create feature vector from raw images.\n",
    "\n",
    "Borrow from https://github.com/uzh-rpg/rpg_public_dronet\n",
    "\n",
    "Note:\n",
    "    Layer naming convention: `layer_name(str) + stage(int) + block(str)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a convolutional block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, num_filters, shape_filters, strides, stage):\n",
    "    \"\"\"\n",
    "    Implementation of convolutional block in Residual network\n",
    "    \n",
    "    Input:\n",
    "        X (tensor): input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "        num_filters (list of 3 ints): list of number of filters\n",
    "        shape_filters (list of 3 ints): list of filters' shape\n",
    "        strides (list of 3 ints): list of strides\n",
    "        stage (int): stage of this convolutional block in the whole ResNet\n",
    "        \n",
    "    Output:\n",
    "        tensor of shape (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # retrieve filters shape from filters\n",
    "    n1, n2, n3 = num_filters\n",
    "    f1, f2, f3 = shape_filters\n",
    "    \n",
    "    # retrieve strides from strides\n",
    "    s1, s2, s3 = strides\n",
    "    \n",
    "    # create name\n",
    "    bn_name_base = 'bn_' + str(stage) + '_'\n",
    "    conv_name_base = 'conv_' + str(stage) + '_'\n",
    "    \n",
    "    # save value of X\n",
    "    X_shorcut = X\n",
    "    \n",
    "    # First component of the main path\n",
    "    X = keras.layers.normalization.BatchNormalization(name=bn_name_base + 'a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(n1, (f1, f1), strides=[s1, s1], padding='same',\n",
    "               name=conv_name_base + 'a',\n",
    "               kernel_initializer='he_normal',\n",
    "               kernel_regularizer=regularizers.l2(1e-4))(X)\n",
    "    \n",
    "    # Second component of the main path\n",
    "    X = keras.layers.normalization.BatchNormalization(name=bn_name_base + 'b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(n2, (f2, f2), strides=[s2, s2], padding='same',\n",
    "               name=conv_name_base + 'b',\n",
    "               kernel_initializer='he_normal',\n",
    "               kernel_regularizer=regularizers.l2(1e-4))(X)\n",
    "    \n",
    "    # Short-cut\n",
    "    X_shorcut = Conv2D(n3, (f3, f3), strides=[s3, s3], padding='same', name=conv_name_base + 'c')(X_shorcut)\n",
    "    \n",
    "    X = add([X, X_shorcut])\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble 3 convolutional block to make a ResNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet8_clean(input_shape):\n",
    "    \"\"\"\n",
    "    Define encoder architecture as ResNet8\n",
    "    \n",
    "    Input:\n",
    "        input_shape (list of ints): shape of input image [n_H, n_W, n_C]\n",
    "        \n",
    "    Output:\n",
    "        model: a Model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input\n",
    "    X_input = Input(shape=input_shape)\n",
    "    \n",
    "    # Apply 1st convolution & max pooling on input\n",
    "    X = Conv2D(32, (5, 5), strides=[2,2], padding='same', name='conv_0')(X_input)\n",
    "    X = MaxPooling2D(pool_size=(3, 3), strides=[2,2])(X) \n",
    "    \n",
    "    # First convolutional block\n",
    "    X = convolutional_block(X, [32, 32, 32], [3, 3, 1], [2, 1, 2], stage=1)\n",
    "    \n",
    "    # Second convolutional block\n",
    "    X = convolutional_block(X, [64, 64, 64], [3, 3, 1], [2, 1, 2], stage=2)\n",
    "    \n",
    "    # Third convolutional block\n",
    "    X = convolutional_block(X, [128, 128, 128], [3, 3, 1], [2, 1, 2], stage=3)\n",
    "    \n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs=[X_input], outputs=[X])\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model & load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py:210: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv2D)                 (None, 100, 100, 32) 832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 49, 49, 32)   0           conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_a (BatchNormalization)     (None, 49, 49, 32)   128         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 49, 49, 32)   0           bn_1_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_a (Conv2D)               (None, 25, 25, 32)   9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_b (BatchNormalization)     (None, 25, 25, 32)   128         conv_1_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 25, 25, 32)   0           bn_1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_b (Conv2D)               (None, 25, 25, 32)   9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_c (Conv2D)               (None, 25, 25, 32)   1056        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 25, 32)   0           conv_1_b[0][0]                   \n",
      "                                                                 conv_1_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_a (BatchNormalization)     (None, 25, 25, 32)   128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 25, 25, 32)   0           bn_2_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_a (Conv2D)               (None, 13, 13, 64)   18496       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_b (BatchNormalization)     (None, 13, 13, 64)   256         conv_2_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 13, 13, 64)   0           bn_2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_b (Conv2D)               (None, 13, 13, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_c (Conv2D)               (None, 13, 13, 64)   2112        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 13, 13, 64)   0           conv_2_b[0][0]                   \n",
      "                                                                 conv_2_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_3_a (BatchNormalization)     (None, 13, 13, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 13, 13, 64)   0           bn_3_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_a (Conv2D)               (None, 7, 7, 128)    73856       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_3_b (BatchNormalization)     (None, 7, 7, 128)    512         conv_3_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 128)    0           bn_3_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_b (Conv2D)               (None, 7, 7, 128)    147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_c (Conv2D)               (None, 7, 7, 128)    8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 7, 7, 128)    0           conv_3_b[0][0]                   \n",
      "                                                                 conv_3_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6272)         0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 6272)         0           flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 309,088\n",
      "Trainable params: 308,384\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "encoder = resnet8_clean([200, 200, 1])\n",
    "encoder.load_weights('./model/named_resnet8_best_weights.h5', by_name=True)\n",
    "\n",
    "# freeze weights of encoder\n",
    "for l in encoder.layers:\n",
    "    l.trainable = False\n",
    "    \n",
    "encoder.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is needed to add encoder to computation graph\n",
    "_X = np.random.randn(1, 200, 200, 1)\n",
    "encoder.predict(_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "This model decode the feature vector created by the Encoder to produce the prediction for the `PLANNING_HORIZON` (in form of classes of steering angles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(input_shape, planning_horizon):\n",
    "    \"\"\"\n",
    "    Define a network of 3 dense layer\n",
    "    \n",
    "    Input:\n",
    "        input_shape (list of ints)\n",
    "        num_classes (int)\n",
    "        \n",
    "    Output:\n",
    "        Model instance\n",
    "    \"\"\"\n",
    "    X_input = Input(shape=input_shape)\n",
    "    \n",
    "    X = Dropout(0.5)(X_input)\n",
    "    \n",
    "    X = Dense(500, activation='relu', kernel_regularizer=regularizers.l2(1e-2))(X)\n",
    "    \n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    X = Dense(200, activation='relu', kernel_regularizer=regularizers.l2(1e-2))(X)\n",
    "     \n",
    "    y = Dense(planning_horizon, activation=None)(X)\n",
    "        \n",
    "    model = Model(inputs=[X_input], outputs=[y])\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 18816)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 18816)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               9408500   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 25)                5025      \n",
      "=================================================================\n",
      "Total params: 9,513,725\n",
      "Trainable params: 9,513,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "decoder = fully_connected([3 * 6272], 25)\n",
    "\n",
    "decoder.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator\n",
    "\n",
    "This class preprocesses training examples, form traning batches and fit batches to network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, dataset_csv, batch_size=1, \n",
    "                 encoder_input_shape=(200, 200), \n",
    "                 encoder_output_shape=6272, \n",
    "                 shuffle=True):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            dataset_csv (string): path to csv contains dataset\n",
    "            batch_size (int): size of a training batch\n",
    "            encoder_input_shape (tuple): shape of tensor inputted to encoder\n",
    "            encoder_output_shape (int): size of vector outputted by encdoer\n",
    "            shuffle (bool): shuffle dataset after 1 epoch\n",
    "        \"\"\"\n",
    "        \n",
    "        self.df = pd.read_csv(dataset_csv)\n",
    "        self.batch_size = batch_size\n",
    "        self.img_shape = encoder_input_shape\n",
    "        self.encoder_output_shape = encoder_output_shape\n",
    "        self.shuffle = shuffle\n",
    "        # invoke on_epoch_end to create shuffle training dataset\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Output:\n",
    "            the number of batches per epoch\n",
    "        \"\"\"\n",
    "        return int(np.floor(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __data_generation(self, list_indexes):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            list_indexes (list): list of indexes of training sample in this batch\n",
    "        \n",
    "        Output:\n",
    "            X (np.ndarray): feature vector provided by encoder, shape (batch_size, 3*6272)\n",
    "            y (np.ndarray): label vector, shape (batch_size, 25)\n",
    "        \"\"\"\n",
    "        \n",
    "        X = np.zeros((self.batch_size, 3*6272))\n",
    "        y = np.zeros((self.batch_size, 25))\n",
    "        \n",
    "        img_path_prefix = '/home/user/Bureau/Dataset/udacity/'\n",
    "        \n",
    "        # Iterate through each idx in training batch\n",
    "        for i, idx in enumerate(list_indexes): \n",
    "            file_names_list = self.df.iloc[idx].X[2: -2].split(\"', '\")\n",
    "            # generate feature vector for each training sample in the batch\n",
    "            encoder_X = np.zeros((3, self.img_shape[0], self.img_shape[1], 1))\n",
    "            for j, name in enumerate(file_names_list):\n",
    "                # read image\n",
    "                img = cv.imread(img_path_prefix + name, 0)\n",
    "                \n",
    "                # resize & reshape image\n",
    "                img = np.float32(cv.resize(img, self.img_shape))\n",
    "                if len(img.shape) == 2:\n",
    "                    img = img.reshape((img.shape[0], img.shape[1], 1))\n",
    "                \n",
    "                # add img to input tensor of encoder\n",
    "                encoder_X[j, :, :, :] = img\n",
    "            \n",
    "            # pass tensor of imgs through encoder to get features vector \n",
    "            X[i, :] = encoder.predict(encoder_X).reshape(1, -1)\n",
    "            \n",
    "            # get label\n",
    "            y[i, :] = np.array([float(angle) for angle in self.df.iloc[idx].steering_angles[1: -1].split(\", \")])\n",
    "        return X, y\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Generate one batch of data\n",
    "        \n",
    "        Input:\n",
    "            index (int): index of the first training sample\n",
    "        \"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        list_indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        # if (index + 1) * self.batch_size > len(self.indexes), \n",
    "        # list_indexes = [index * self.batch_size: len(self.indexes)]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_indexes)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Updates indexes after each epoch\n",
    "        \"\"\"\n",
    "        self.indexes = np.arange(len(self.df))  # array of indexes of training dataset\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "687/687 [==============================] - 74s 108ms/step - loss: 4.1370 - val_loss: 2.0704\n",
      "Epoch 2/10\n",
      "687/687 [==============================] - 73s 106ms/step - loss: 1.6676 - val_loss: 1.2827\n",
      "Epoch 3/10\n",
      "687/687 [==============================] - 73s 106ms/step - loss: 1.0162 - val_loss: 0.7609\n",
      "Epoch 4/10\n",
      "687/687 [==============================] - 74s 108ms/step - loss: 0.5837 - val_loss: 0.4254\n",
      "Epoch 5/10\n",
      "687/687 [==============================] - 73s 106ms/step - loss: 0.3385 - val_loss: 0.2424\n",
      "Epoch 6/10\n",
      "687/687 [==============================] - 73s 106ms/step - loss: 0.1867 - val_loss: 0.1343\n",
      "Epoch 7/10\n",
      "687/687 [==============================] - 73s 106ms/step - loss: 0.1099 - val_loss: 0.0814\n",
      "Epoch 8/10\n",
      "687/687 [==============================] - 73s 106ms/step - loss: 0.0747 - val_loss: 0.0582\n",
      "Epoch 9/10\n",
      "687/687 [==============================] - 73s 106ms/step - loss: 0.0559 - val_loss: 0.0445\n",
      "Epoch 10/10\n",
      "687/687 [==============================] - 73s 106ms/step - loss: 0.0462 - val_loss: 0.0380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa6150faa58>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters of datagenerator\n",
    "params = {'batch_size': 5, \n",
    "         'encoder_input_shape': (200, 200), \n",
    "         'encoder_output_shape': 6272, \n",
    "         'shuffle': True}\n",
    "\n",
    "training_generator = DataGenerator('./data/hybrid_training.csv', **params)\n",
    "validation_generator = DataGenerator('./data/hybrid_validation.csv', **params)\n",
    "\n",
    "decoder.fit_generator(generator=training_generator,\n",
    "                      validation_data=validation_generator,\n",
    "                      epochs=10,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save decoder weights\n",
    "decoder.save_weights('./model/decoder_weights_MAY11.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
