{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.merge import add\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition\n",
    "\n",
    "## Encoder\n",
    "The role of this model is to create feature vector from raw images.\n",
    "\n",
    "Borrow from https://github.com/uzh-rpg/rpg_public_dronet\n",
    "\n",
    "Note:\n",
    "    Layer naming convention: `layer_name(str) + stage(int) + block(str)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a convolutional block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, num_filters, shape_filters, strides, stage):\n",
    "    \"\"\"\n",
    "    Implementation of convolutional block in Residual network\n",
    "    \n",
    "    Input:\n",
    "        X (tensor): input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "        num_filters (list of 3 ints): list of number of filters\n",
    "        shape_filters (list of 3 ints): list of filters' shape\n",
    "        strides (list of 3 ints): list of strides\n",
    "        stage (int): stage of this convolutional block in the whole ResNet\n",
    "        \n",
    "    Output:\n",
    "        tensor of shape (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # retrieve filters shape from filters\n",
    "    n1, n2, n3 = num_filters\n",
    "    f1, f2, f3 = shape_filters\n",
    "    \n",
    "    # retrieve strides from strides\n",
    "    s1, s2, s3 = strides\n",
    "    \n",
    "    # create name\n",
    "    bn_name_base = 'bn_' + str(stage) + '_'\n",
    "    conv_name_base = 'conv_' + str(stage) + '_'\n",
    "    \n",
    "    # save value of X\n",
    "    X_shorcut = X\n",
    "    \n",
    "    # First component of the main path\n",
    "    X = keras.layers.normalization.BatchNormalization(name=bn_name_base + 'a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(n1, (f1, f1), strides=[s1, s1], padding='same',\n",
    "               name=conv_name_base + 'a',\n",
    "               kernel_initializer='he_normal',\n",
    "               kernel_regularizer=regularizers.l2(1e-4))(X)\n",
    "    \n",
    "    # Second component of the main path\n",
    "    X = keras.layers.normalization.BatchNormalization(name=bn_name_base + 'b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(n2, (f2, f2), strides=[s2, s2], padding='same',\n",
    "               name=conv_name_base + 'b',\n",
    "               kernel_initializer='he_normal',\n",
    "               kernel_regularizer=regularizers.l2(1e-4))(X)\n",
    "    \n",
    "    # Short-cut\n",
    "    X_shorcut = Conv2D(n3, (f3, f3), strides=[s3, s3], padding='same', name=conv_name_base + 'c')(X_shorcut)\n",
    "    \n",
    "    X = add([X, X_shorcut])\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble 3 convolutional block to make a ResNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet8_clean(input_shape):\n",
    "    \"\"\"\n",
    "    Define encoder architecture as ResNet8\n",
    "    \n",
    "    Input:\n",
    "        input_shape (list of ints): shape of input image [n_H, n_W, n_C]\n",
    "        \n",
    "    Output:\n",
    "        model: a Model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input\n",
    "    X_input = Input(shape=input_shape)\n",
    "    \n",
    "    # Apply 1st convolution & max pooling on input\n",
    "    X = Conv2D(32, (5, 5), strides=[2,2], padding='same', name='conv_0')(X_input)\n",
    "    X = MaxPooling2D(pool_size=(3, 3), strides=[2,2])(X) \n",
    "    \n",
    "    # First convolutional block\n",
    "    X = convolutional_block(X, [32, 32, 32], [3, 3, 1], [2, 1, 2], stage=1)\n",
    "    \n",
    "    # Second convolutional block\n",
    "    X = convolutional_block(X, [64, 64, 64], [3, 3, 1], [2, 1, 2], stage=2)\n",
    "    \n",
    "    # Third convolutional block\n",
    "    X = convolutional_block(X, [128, 128, 128], [3, 3, 1], [2, 1, 2], stage=3)\n",
    "    \n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs=[X_input], outputs=[X])\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model & load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py:210: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv2D)                 (None, 100, 100, 32) 832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 49, 49, 32)   0           conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_a (BatchNormalization)     (None, 49, 49, 32)   128         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 49, 49, 32)   0           bn_1_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_a (Conv2D)               (None, 25, 25, 32)   9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_b (BatchNormalization)     (None, 25, 25, 32)   128         conv_1_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 25, 25, 32)   0           bn_1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_b (Conv2D)               (None, 25, 25, 32)   9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_c (Conv2D)               (None, 25, 25, 32)   1056        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 25, 32)   0           conv_1_b[0][0]                   \n",
      "                                                                 conv_1_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_a (BatchNormalization)     (None, 25, 25, 32)   128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 25, 25, 32)   0           bn_2_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_a (Conv2D)               (None, 13, 13, 64)   18496       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_b (BatchNormalization)     (None, 13, 13, 64)   256         conv_2_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 13, 13, 64)   0           bn_2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_b (Conv2D)               (None, 13, 13, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_c (Conv2D)               (None, 13, 13, 64)   2112        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 13, 13, 64)   0           conv_2_b[0][0]                   \n",
      "                                                                 conv_2_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_3_a (BatchNormalization)     (None, 13, 13, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 13, 13, 64)   0           bn_3_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_a (Conv2D)               (None, 7, 7, 128)    73856       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_3_b (BatchNormalization)     (None, 7, 7, 128)    512         conv_3_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 128)    0           bn_3_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_b (Conv2D)               (None, 7, 7, 128)    147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_c (Conv2D)               (None, 7, 7, 128)    8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 7, 7, 128)    0           conv_3_b[0][0]                   \n",
      "                                                                 conv_3_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6272)         0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 6272)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 6272)         0           activation_7[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 309,088\n",
      "Trainable params: 308,384\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "encoder = resnet8_clean([200, 200, 1])\n",
    "encoder.load_weights('./model/named_resnet8_best_weights.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv_0/kernel:0',\n",
       " 'conv_0/bias:0',\n",
       " 'bn_1_a/gamma:0',\n",
       " 'bn_1_a/beta:0',\n",
       " 'bn_1_a/moving_mean:0',\n",
       " 'bn_1_a/moving_variance:0',\n",
       " 'conv_1_a/kernel:0',\n",
       " 'conv_1_a/bias:0',\n",
       " 'bn_1_b/gamma:0',\n",
       " 'bn_1_b/beta:0',\n",
       " 'bn_1_b/moving_mean:0',\n",
       " 'bn_1_b/moving_variance:0',\n",
       " 'conv_1_b/kernel:0',\n",
       " 'conv_1_b/bias:0',\n",
       " 'conv_1_c/kernel:0',\n",
       " 'conv_1_c/bias:0',\n",
       " 'bn_2_a/gamma:0',\n",
       " 'bn_2_a/beta:0',\n",
       " 'bn_2_a/moving_mean:0',\n",
       " 'bn_2_a/moving_variance:0',\n",
       " 'conv_2_a/kernel:0',\n",
       " 'conv_2_a/bias:0',\n",
       " 'bn_2_b/gamma:0',\n",
       " 'bn_2_b/beta:0',\n",
       " 'bn_2_b/moving_mean:0',\n",
       " 'bn_2_b/moving_variance:0',\n",
       " 'conv_2_b/kernel:0',\n",
       " 'conv_2_b/bias:0',\n",
       " 'conv_2_c/kernel:0',\n",
       " 'conv_2_c/bias:0',\n",
       " 'bn_3_a/gamma:0',\n",
       " 'bn_3_a/beta:0',\n",
       " 'bn_3_a/moving_mean:0',\n",
       " 'bn_3_a/moving_variance:0',\n",
       " 'conv_3_a/kernel:0',\n",
       " 'conv_3_a/bias:0',\n",
       " 'bn_3_b/gamma:0',\n",
       " 'bn_3_b/beta:0',\n",
       " 'bn_3_b/moving_mean:0',\n",
       " 'bn_3_b/moving_variance:0',\n",
       " 'conv_3_b/kernel:0',\n",
       " 'conv_3_b/bias:0',\n",
       " 'conv_3_c/kernel:0',\n",
       " 'conv_3_c/bias:0']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [weight.name for layer in encoder.layers for weight in layer.weights]\n",
    "weights = encoder.get_weights()\n",
    "\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 32, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.03906486,  0.23744462,  0.35682636, ..., -0.15168019,\n",
       "          -0.09894565,  0.10449842],\n",
       "         [ 0.08876824, -0.04708504, -0.5501143 , ...,  0.35634387,\n",
       "           0.98491377,  0.17439887],\n",
       "         [ 0.08548965, -0.03150511, -0.2497131 , ...,  0.32054433,\n",
       "           0.6079249 , -0.26140153],\n",
       "         ...,\n",
       "         [-0.17021403, -0.07588131,  0.01981616, ..., -0.26841697,\n",
       "           0.4311797 , -0.16715825],\n",
       "         [ 0.10458679, -0.24335292, -0.13646314, ..., -0.168561  ,\n",
       "          -0.06483505, -0.07373277],\n",
       "         [ 0.18375537, -0.17555152, -0.13670585, ...,  0.08006119,\n",
       "           0.29586527,  0.01597549]]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d_1_a_kernel = weights[14]\n",
    "print(conv2d_1_a_kernel.shape)\n",
    "conv2d_1_a_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "This model decode the feature vector created by the Encoder to produce the prediction for the `PLANNING_HORIZON` (in form of classes of steering angles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['activation_1',\n",
       " 'activation_2',\n",
       " 'activation_3',\n",
       " 'activation_4',\n",
       " 'activation_5',\n",
       " 'activation_6',\n",
       " 'activation_7',\n",
       " 'activation_8',\n",
       " 'add_1',\n",
       " 'add_2',\n",
       " 'add_3',\n",
       " 'batch_normalization_1',\n",
       " 'batch_normalization_2',\n",
       " 'batch_normalization_3',\n",
       " 'batch_normalization_4',\n",
       " 'batch_normalization_5',\n",
       " 'batch_normalization_6',\n",
       " 'conv2d_1',\n",
       " 'conv2d_10',\n",
       " 'conv2d_2',\n",
       " 'conv2d_3',\n",
       " 'conv2d_4',\n",
       " 'conv2d_5',\n",
       " 'conv2d_6',\n",
       " 'conv2d_7',\n",
       " 'conv2d_8',\n",
       " 'conv2d_9',\n",
       " 'dense_1',\n",
       " 'dense_2',\n",
       " 'dropout_1',\n",
       " 'flatten_1',\n",
       " 'input_1',\n",
       " 'max_pooling2d_1']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = h5py.File('./model/best_weights.h5')\n",
    "allKeys = w1.keys()\n",
    "list(allKeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 32, 32)\n",
      "[[[[ 0.03906486  0.23744462  0.35682636 ... -0.15168019 -0.09894565\n",
      "     0.10449842]\n",
      "   [ 0.08876824 -0.04708504 -0.5501143  ...  0.35634387  0.98491377\n",
      "     0.17439887]\n",
      "   [ 0.08548965 -0.03150511 -0.2497131  ...  0.32054433  0.6079249\n",
      "    -0.26140153]\n",
      "   ...\n",
      "   [-0.17021403 -0.07588131  0.01981616 ... -0.26841697  0.4311797\n",
      "    -0.16715825]\n",
      "   [ 0.10458679 -0.24335292 -0.13646314 ... -0.168561   -0.06483505\n",
      "    -0.07373277]\n",
      "   [ 0.18375537 -0.17555152 -0.13670585 ...  0.08006119  0.29586527\n",
      "     0.01597549]]]]\n"
     ]
    }
   ],
   "source": [
    "origin_conv2d_2_wts = w1['conv2d_4']['conv2d_4']['kernel:0']\n",
    "origin_conv2d_2_kernel = origin_conv2d_2_wts.value\n",
    "print(origin_conv2d_2_kernel.shape)\n",
    "print(origin_conv2d_2_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = conv2d_1_a_kernel.squeeze() - origin_conv2d_2_kernel.squeeze() \n",
    "np.sum(np.square(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
