{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from new_model.model_utils import resnet_shorten, hybrid_LSTM_training, _classifier, convolutional_block\n",
    "from keras.layers import LSTM, Reshape, Input\n",
    "from keras.models import Model\n",
    "import keras\n",
    "from training_utils import save_model, DataGenerator, generate_dataset\n",
    "\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (200, 200, 1)\n",
    "LSTM_DIM_HIDDEN = 64*2\n",
    "LEN_SPATIAL_HISTORY = 4\n",
    "NUM_CLASS = 73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name of previously trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_encoder_file = \"shared_encoder_resnet8_2019_05_21_17_28.h5\"\n",
    "shared_lstm_file = \"lstm_weights_2019_05_21_17_28.p\"\n",
    "shared_classifier_file = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# 2.Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**------------------------**\n",
    "## 2.1 Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Shared encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py:210: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "shared_encoder = resnet_shorten(IMG_SHAPE, model_name=\"shared_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv2D)                 (None, 100, 100, 32) 832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 49, 49, 32)   0           conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_a (BatchNormalization)     (None, 49, 49, 32)   128         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 49, 49, 32)   0           bn_1_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_a (Conv2D)               (None, 25, 25, 32)   9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_b (BatchNormalization)     (None, 25, 25, 32)   128         conv_1_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 25, 25, 32)   0           bn_1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_b (Conv2D)               (None, 25, 25, 32)   9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_c (Conv2D)               (None, 25, 25, 32)   1056        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 25, 32)   0           conv_1_b[0][0]                   \n",
      "                                                                 conv_1_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_a (BatchNormalization)     (None, 25, 25, 32)   128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 25, 25, 32)   0           bn_2_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_a (Conv2D)               (None, 13, 13, 64)   18496       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_b (BatchNormalization)     (None, 13, 13, 64)   256         conv_2_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 13, 13, 64)   0           bn_2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_b (Conv2D)               (None, 13, 13, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_c (Conv2D)               (None, 13, 13, 64)   2112        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 13, 13, 64)   0           conv_2_b[0][0]                   \n",
      "                                                                 conv_2_c[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 78,560\n",
      "Trainable params: 78,240\n",
      "Non-trainable params: 320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "shared_encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Separate encoder\n",
    "\n",
    "This is a convolution block of ResNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _separate_encoder(input_shape, num_filters, shape_filters, strides, stage, model_name):\n",
    "    \"\"\"\n",
    "    Create a model from the function named \"convolutional_block\". This model is later used as a layer\n",
    "    in the full hybrid model\n",
    "    \n",
    "    Input: \n",
    "        input_shape (tuple): shape of feature vectors created by shared_encoder\n",
    "        num_filters (list): number of filters of each Conv2D layer of this model\n",
    "        strides (list): size of strides of each Conv2D layer\n",
    "        stage: must set to be None\n",
    "        model_name (str):\n",
    "        \n",
    "    Output:\n",
    "        keras Model instance\n",
    "    \"\"\"\n",
    "    assert(stage is None)\n",
    "    \n",
    "    # define input\n",
    "    X_input = Input(shape=input_shape)\n",
    "    \n",
    "    # pass input through a convolutional block of ResNet\n",
    "    X = convolutional_block(X_input, num_filters, shape_filters, strides, stage=None, model_name=model_name)\n",
    "    \n",
    "    # define model\n",
    "    model = Model(inputs=[X_input], outputs=[X], name=model_name)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define config of separate encoder\n",
    "s_input_shape = (13, 13, 64)  # shape of output of shared encoder\n",
    "s_num_filters = [128, 128, 128]\n",
    "s_shape_filters = [3, 3, 1]\n",
    "s_strides = [2, 1, 2]\n",
    "\n",
    "sep_encoder_list = [_separate_encoder(s_input_shape, s_num_filters, s_shape_filters, s_strides, \n",
    "                                      stage=None, model_name=\"sep_en_%d\" % i) \n",
    "                   for i in range(LEN_SPATIAL_HISTORY)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 13, 13, 64)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sep_en_0_bn_a (BatchNormalizati (None, 13, 13, 64)   256         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 13, 13, 64)   0           sep_en_0_bn_a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sep_en_0_conv_a (Conv2D)        (None, 7, 7, 128)    73856       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sep_en_0_bn_b (BatchNormalizati (None, 7, 7, 128)    512         sep_en_0_conv_a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 128)    0           sep_en_0_bn_b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sep_en_0_conv_b (Conv2D)        (None, 7, 7, 128)    147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sep_en_0_conv_c (Conv2D)        (None, 7, 7, 128)    8320        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 7, 7, 128)    0           sep_en_0_conv_b[0][0]            \n",
      "                                                                 sep_en_0_conv_c[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 230,528\n",
      "Trainable params: 230,144\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sep_encoder_list[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**------------------------**\n",
    "## 2.2 Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Define LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_cell = LSTM(LSTM_DIM_HIDDEN, return_state=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Define Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = _classifier(input_shape=(LSTM_DIM_HIDDEN, ), num_class=NUM_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 73)                18761     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 73)                0         \n",
      "=================================================================\n",
      "Total params: 51,785\n",
      "Trainable params: 51,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshapor = Reshape((1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattener = keras.layers.Flatten()\n",
    "activator = keras.layers.Activation('relu')\n",
    "\n",
    "\n",
    "def model_shared_private_encoder(image_shape, shared_encoder, sep_encoder_list, LSTM_cell, \n",
    "                                 LSTM_dim_hidden_state, Ty):\n",
    "    \"\"\"\n",
    "    Define full model with both shared & private encoder\n",
    "    \n",
    "    Input:\n",
    "        image_shape (tuple): shape of input image\n",
    "        shared_encoder (keras.Model): shared model used to extract low level feature vector from input image\n",
    "        sep_encoder_list (list): list of keras.Model storing separate encoder\n",
    "        LSTM_cell (keras.layers): shared LSTM layer\n",
    "        LSTM_dim_hidden_state (int): dimension of LSTM_cell's hidden state\n",
    "        Ty (int): length of spatial history\n",
    "    \n",
    "    Output:\n",
    "        keras Model instance\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    X_input_list = [Input(shape=image_shape) for i in range(Ty)]\n",
    "    \n",
    "    # pass each input through shared encoder\n",
    "    shared_encoded_X = [shared_encoder(X) for X in X_input_list]\n",
    "    \n",
    "    # pass each encoded_X through its own convolution block\n",
    "    separate_encoded_X = [separate_encoder(X) \n",
    "                          for separate_encoder, X in zip(sep_encoder_list, shared_encoded_X)]\n",
    "    \n",
    "    # initialize input & cell state\n",
    "    a_0 = Input(shape=(LSTM_dim_hidden_state, ))  \n",
    "    c_0 = Input(shape=(LSTM_dim_hidden_state, ))\n",
    "    \n",
    "    a = a_0\n",
    "    c = c_0\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    # Decode\n",
    "    for encoded_X in separate_encoded_X:\n",
    "        # flatten & activate encoded_X \n",
    "        X = flattener(encoded_X)\n",
    "        X = activator(X)\n",
    "        \n",
    "        # perform 1 step of LSTM cell\n",
    "        X = reshapor(encoded_X)\n",
    "        a, _, c = LSTM_cell(X, initial_state=[a, c])\n",
    "        \n",
    "        # apply regressor to the hidden state of LSTM_cell\n",
    "        out = classifier(a)\n",
    "        \n",
    "        # append out to outputs\n",
    "        outputs.append(out)\n",
    "    \n",
    "    # define model\n",
    "    model = Model(inputs=X_input_list + [a_0, c_0], outputs=outputs)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model = model_shared_private_encoder(IMG_SHAPE, shared_encoder, sep_encoder_list, LSTM_cell, \n",
    "                                            LSTM_DIM_HIDDEN, LEN_SPATIAL_HISTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_encoder (Model)          (None, 13, 13, 64)   78560       input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sep_en_0 (Model)                (None, 7, 7, 128)    230528      shared_encoder[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 6272)      0           sep_en_0[1][0]                   \n",
      "                                                                 sep_en_1[1][0]                   \n",
      "                                                                 sep_en_2[1][0]                   \n",
      "                                                                 sep_en_3[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sep_en_1 (Model)                (None, 7, 7, 128)    230528      shared_encoder[2][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 128), (None, 3277312     reshape_1[0][0]                  \n",
      "                                                                 input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "                                                                 reshape_1[1][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 reshape_1[2][0]                  \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "                                                                 reshape_1[3][0]                  \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[2][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "sep_en_2 (Model)                (None, 7, 7, 128)    230528      shared_encoder[3][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sep_en_3 (Model)                (None, 7, 7, 128)    230528      shared_encoder[4][0]             \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 73)           51785       lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,329,769\n",
      "Trainable params: 4,327,913\n",
      "Non-trainable params: 1,856\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hybrid_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Load weights & compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load shared_encoder\n",
    "shared_encoder.load_weights(\"./new_model/weights/shared_encoder/%s\" % shared_encoder_file, by_name=True)\n",
    "\n",
    "# Load shared LSTM\n",
    "with open('./new_model/weights/shared_lstm/%s' % shared_lstm_file, 'rb') as fp:\n",
    "    lstm_weights_dict = pickle.load(fp)\n",
    "    \n",
    "lstm_weights = []\n",
    "for k in lstm_weights_dict.keys():\n",
    "    lstm_weights.append(lstm_weights_dict[k])\n",
    "    \n",
    "LSTM_cell.set_weights(lstm_weights)\n",
    "\n",
    "# Load shared classifier\n",
    "classifier.load_weights(\"./new_model/weights/shared_classifier/%s\" % shared_classifier_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "otim = keras.optimizers.Adam(lr=0.25, decay=0.001)\n",
    "hybrid_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "param_train = {'img_shape': IMG_SHAPE, \n",
    "             'Ty': LEN_SPATIAL_HISTORY, \n",
    "             'num_class': NUM_CLASS, \n",
    "             'batch_size': batch_size, \n",
    "             'shuffle': True, \n",
    "             'additional_input_for_LSTM': True, \n",
    "             'LSTM_dim_hidden_states': LSTM_DIM_HIDDEN}\n",
    "\n",
    "train_gen = DataGenerator(\"./new_data/widthen_bin_training_CH2_only.csv\", **param_train)\n",
    "\n",
    "param_val = {'img_shape': IMG_SHAPE, \n",
    "             'num_class': NUM_CLASS, \n",
    "             'Ty': LEN_SPATIAL_HISTORY, \n",
    "             'LSTM_dim_hidden_states': LSTM_DIM_HIDDEN, \n",
    "             'color_img': False}\n",
    "X_val, y_val = generate_dataset(\"./new_data/widthen_bin_validation_CH2_only.csv\", **param_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = time.strftime(\"%Y_%m_%d_%H_%M\")\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir='./logs/' + time_str,  \n",
    "                                          batch_size=batch_size, \n",
    "                                          update_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "569/569 [==============================] - 204s 359ms/step - loss: 9.1436 - model_1_loss: 2.2973 - model_1_acc: 0.3063 - model_1_acc_1: 0.2912 - model_1_acc_2: 0.3133 - model_1_acc_3: 0.3011 - val_loss: 9.1558 - val_model_1_loss: 2.2667 - val_model_1_acc: 0.3121 - val_model_1_acc_1: 0.2790 - val_model_1_acc_2: 0.3284 - val_model_1_acc_3: 0.3037\n",
      "Epoch 12/20\n",
      "569/569 [==============================] - 201s 354ms/step - loss: 9.1229 - model_1_loss: 2.2828 - model_1_acc: 0.3008 - model_1_acc_1: 0.2942 - model_1_acc_2: 0.2976 - model_1_acc_3: 0.2901 - val_loss: 9.1008 - val_model_1_loss: 2.2769 - val_model_1_acc: 0.3185 - val_model_1_acc_1: 0.3165 - val_model_1_acc_2: 0.3289 - val_model_1_acc_3: 0.2869\n",
      "Epoch 13/20\n",
      "569/569 [==============================] - 202s 355ms/step - loss: 9.1394 - model_1_loss: 2.2868 - model_1_acc: 0.3029 - model_1_acc_1: 0.2905 - model_1_acc_2: 0.2965 - model_1_acc_3: 0.3094 - val_loss: 9.1101 - val_model_1_loss: 2.2544 - val_model_1_acc: 0.3151 - val_model_1_acc_1: 0.2795 - val_model_1_acc_2: 0.2514 - val_model_1_acc_3: 0.3175\n",
      "Epoch 14/20\n",
      "569/569 [==============================] - 201s 354ms/step - loss: 9.1071 - model_1_loss: 2.2793 - model_1_acc: 0.3104 - model_1_acc_1: 0.2923 - model_1_acc_2: 0.3010 - model_1_acc_3: 0.2955 - val_loss: 9.1902 - val_model_1_loss: 2.2874 - val_model_1_acc: 0.2825 - val_model_1_acc_1: 0.2849 - val_model_1_acc_2: 0.2998 - val_model_1_acc_3: 0.2583\n",
      "Epoch 15/20\n",
      "569/569 [==============================] - 201s 353ms/step - loss: 9.1205 - model_1_loss: 2.2832 - model_1_acc: 0.2940 - model_1_acc_1: 0.2991 - model_1_acc_2: 0.2967 - model_1_acc_3: 0.3003 - val_loss: 9.0854 - val_model_1_loss: 2.2578 - val_model_1_acc: 0.2904 - val_model_1_acc_1: 0.3022 - val_model_1_acc_2: 0.2993 - val_model_1_acc_3: 0.3086\n",
      "Epoch 16/20\n",
      "569/569 [==============================] - 202s 356ms/step - loss: 9.1742 - model_1_loss: 2.2809 - model_1_acc: 0.2999 - model_1_acc_1: 0.2988 - model_1_acc_2: 0.2830 - model_1_acc_3: 0.2960 - val_loss: 9.1696 - val_model_1_loss: 2.2623 - val_model_1_acc: 0.3072 - val_model_1_acc_1: 0.2988 - val_model_1_acc_2: 0.3057 - val_model_1_acc_3: 0.3032\n",
      "Epoch 17/20\n",
      "569/569 [==============================] - 203s 356ms/step - loss: 9.2086 - model_1_loss: 2.2669 - model_1_acc: 0.2864 - model_1_acc_1: 0.2918 - model_1_acc_2: 0.2967 - model_1_acc_3: 0.3134 - val_loss: 9.1124 - val_model_1_loss: 2.2345 - val_model_1_acc: 0.2770 - val_model_1_acc_1: 0.2874 - val_model_1_acc_2: 0.3037 - val_model_1_acc_3: 0.3131\n",
      "Epoch 18/20\n",
      "569/569 [==============================] - 204s 358ms/step - loss: 9.2257 - model_1_loss: 2.2966 - model_1_acc: 0.2873 - model_1_acc_1: 0.2949 - model_1_acc_2: 0.2889 - model_1_acc_3: 0.2981 - val_loss: 9.0700 - val_model_1_loss: 2.2443 - val_model_1_acc: 0.2499 - val_model_1_acc_1: 0.3002 - val_model_1_acc_2: 0.2933 - val_model_1_acc_3: 0.3121\n",
      "Epoch 19/20\n",
      "569/569 [==============================] - 203s 357ms/step - loss: 9.2096 - model_1_loss: 2.2918 - model_1_acc: 0.2947 - model_1_acc_1: 0.2871 - model_1_acc_2: 0.2867 - model_1_acc_3: 0.2939 - val_loss: 9.3282 - val_model_1_loss: 2.3627 - val_model_1_acc: 0.2998 - val_model_1_acc_1: 0.3007 - val_model_1_acc_2: 0.2869 - val_model_1_acc_3: 0.3116\n",
      "Epoch 20/20\n",
      "569/569 [==============================] - 203s 356ms/step - loss: 9.1934 - model_1_loss: 2.2915 - model_1_acc: 0.2892 - model_1_acc_1: 0.2961 - model_1_acc_2: 0.2978 - model_1_acc_3: 0.3015 - val_loss: 9.1482 - val_model_1_loss: 2.2715 - val_model_1_acc: 0.2840 - val_model_1_acc_1: 0.3027 - val_model_1_acc_2: 0.2914 - val_model_1_acc_3: 0.2548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0d49b53978>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_model.fit_generator(train_gen,\n",
    "                           epochs=20,\n",
    "                           validation_data=(X_val, y_val),\n",
    "                           initial_epoch=10,\n",
    "                           callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save shared_encoder \n",
    "shared_encoder.save_weights(\"./new_model/weights/shared_encoder/shared_encoder_resnet8_%s.h5\" % time_str)\n",
    "\n",
    "# save shared_lstm\n",
    "lstm_w = LSTM_cell.get_weights()\n",
    "lstm_w_dict ={}\n",
    "lstm_w_dict['0'] = lstm_w[0]\n",
    "lstm_w_dict['1'] = lstm_w[1]\n",
    "lstm_w_dict['2'] = lstm_w[2]\n",
    "\n",
    "with open(\"./new_model/weights/shared_lstm/shared_lstm_weights_%s.p\" % time_str, 'wb') as fp:\n",
    "    pickle.dump(lstm_w_dict, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# save separate encoder\n",
    "for i, sep_encoder in enumerate(sep_encoder_list):\n",
    "    sep_encoder.save_weights(\"./new_model/weights/separate_encoder/sep_encoder_%d_%s.h5\" % (i, time_str))\n",
    "\n",
    "# save classifier\n",
    "classifier.save_weights(\"./new_model/weights/shared_classifier/classifier_%s.h5\" % time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
