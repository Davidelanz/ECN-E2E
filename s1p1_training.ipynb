{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "RRrt34CAVIQT",
    "outputId": "ed9152e4-1e76-4746-cf52-c7326a8f4317"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "import keras.layers as KL\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "from training_utils import gen_classifier_dataset\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ThUT5pmdt1o"
   },
   "source": [
    "# Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ltTijhs9duYJ"
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (200, 200, 1)\n",
    "NUM_LABELS = 5\n",
    "BINS_EDGE = np.load(\"./data/bins_edge.npy\")\n",
    "NUM_CLASSES = len(BINS_EDGE) - 1  \n",
    "\n",
    "with open('./data/classes_weight.json', 'r') as fp:\n",
    "    CLASSES_WEIGHT = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y0s3Put7VIR_"
   },
   "source": [
    "# 1. Model Architect\n",
    "## 1.1 ResNet Block\n",
    "Definition of ResNet block is adapted from https://github.com/uzh-rpg/rpg_public_dronet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CsOw9SduVISS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/davidelanz/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Before first block\n",
    "\n",
    "img_input = Input(shape=IMAGE_SHAPE)\n",
    "\n",
    "x0 = Conv2D(filters = 32, activation = None,\n",
    "            kernel_size = (5, 5), strides=2, \n",
    "            padding='same')(img_input)\n",
    "\n",
    "x0 = MaxPooling2D(pool_size=(3, 3), strides=[2,2])(x0)\n",
    "\n",
    "# x0 is the output of the first three layers\n",
    "#    and the input of the first residual block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GlRHJr_vVISe"
   },
   "outputs": [],
   "source": [
    "def build_residual_block(block_input, filt_size):\n",
    "    \"\"\"\n",
    "    #Define residual block.\n",
    "    #\n",
    "    # Arguments\n",
    "    #   block_input: The input of the block\n",
    "    #   filt_size: Block filter size (convolutional 2D kernel)\n",
    "    #   \n",
    "    # Returns\n",
    "    #   block_output: The output of the block\n",
    "    \"\"\"\n",
    "  \n",
    "    block_output = BatchNormalization()(block_input)\n",
    "    \n",
    "    block_output = Activation('relu')(block_output)\n",
    "\n",
    "    block_output = Conv2D(filters = filt_size, strides=2,\n",
    "                          kernel_size = 3,\n",
    "                          activation = 'linear', padding='same',\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=keras.regularizers.l2(1e-4))(block_output)\n",
    "\n",
    "    block_output = BatchNormalization()(block_output)\n",
    "\n",
    "    block_output = Activation('relu')(block_output)\n",
    "    \n",
    "    block_output = Conv2D(filters = filt_size, strides=1,\n",
    "                          kernel_size = 3,\n",
    "                          activation = 'linear', padding='same',\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=keras.regularizers.l2(1e-4))(block_output)\n",
    "    \n",
    "    return block_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RHYUY-qRVISp"
   },
   "source": [
    "Function to build the block with the convolutional shortcut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJOuERjQVISs"
   },
   "outputs": [],
   "source": [
    "def build_full_block(block_input, filt_size):\n",
    "    \"\"\"\n",
    "    # Define full block.\n",
    "    #\n",
    "    # Arguments\n",
    "    #   block_input: The input of the full block\n",
    "    #   filt_size: Filter size (conv2D kernel)\n",
    "    #   \n",
    "    # Returns\n",
    "    #   block_output: The output of the block\n",
    "    \"\"\"\n",
    "  \n",
    "    # First residual block\n",
    "    x_main = build_residual_block(block_input, filt_size)\n",
    "    # x_main = \"output of the main path\"\n",
    "\n",
    "    # First convolutional shortcut\n",
    "    x_short = Conv2D(filters = filt_size,  strides = 2,\n",
    "                     kernel_size = 1,\n",
    "                     activation = None, padding = 'same')(block_input)\n",
    "    # x_short = \"output of the shortcut\"\n",
    "\n",
    "    # Add the outputs of the residual block and the convolutional shortcut\n",
    "    block_output = keras.layers.add([x_main, x_short])\n",
    "\n",
    "    return block_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2d3qlkriVIS3"
   },
   "source": [
    "Build the three full blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hVopNLRFVIS_"
   },
   "outputs": [],
   "source": [
    "x1 = build_full_block(x0, filt_size = 32 )\n",
    "x2 = build_full_block(x1, filt_size = 64 )\n",
    "x3 = build_full_block(x2, filt_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fGLvoHqdVIT8"
   },
   "source": [
    "Define the flatten layer, apply one time the ReLU activation function and use a dropout of 0.5.\n",
    "\n",
    "Only two Dense layer as output. NVIDIA paper uses 3 Dense layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqgO1FFIVIT-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "x4 = Flatten()(x3)\n",
    "x4 = Activation('relu')(x4) # Apply ReLU to every output from the Flatten layer\n",
    "x4 = Dropout(0.5)(x4) # Conserve only 0.5 of the results\n",
    "\n",
    "# Steering channel (output)\n",
    "steer = Dense(800, activation=\"relu\")(x4)\n",
    "steer = Dropout(0.5)(steer) # Conserve only 0.5 of the results\n",
    "steer = Dense(NUM_CLASSES,activation = \"softmax\")(steer) \n",
    "# Activation:\n",
    "# --> sigmoid = binary classification\n",
    "# --> softmax = categorical classification \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Bqda0JiVIUV"
   },
   "source": [
    "## 1.4 Create Model\n",
    "Finally put everything in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BvdAsxUUVIUW"
   },
   "outputs": [],
   "source": [
    "# Define steering-collision model\n",
    "model = Model(inputs=[img_input], outputs=[steer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "bnxB2MxQoPnX",
    "outputId": "c26fa95e-0839-42ed-f031-8d6e42e63a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(?, 200, 200, 1), dtype=float32)\n",
      "Tensor(\"dense_2/Softmax:0\", shape=(?, 114), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 100, 100, 32) 832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 49, 49, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 49, 49, 32)   128         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 49, 49, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 25, 25, 32)   9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 25, 25, 32)   128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 25, 25, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 25, 25, 32)   9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 25, 25, 32)   1056        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 25, 32)   0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 25, 25, 32)   128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 25, 25, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 13, 13, 64)   18496       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 13, 13, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 13, 13, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 13, 13, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 13, 13, 64)   2112        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 13, 13, 64)   0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 13, 13, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 13, 13, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 7, 7, 128)    73856       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7, 7, 128)    512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 128)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 7, 7, 128)    147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 7, 7, 128)    8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 7, 7, 128)    0           conv2d_9[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6272)         0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 6272)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 6272)         0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 800)          5018400     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 800)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 114)          91314       dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,418,802\n",
      "Trainable params: 5,418,098\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (model.input)\n",
    "print (model.output)\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VM_RdOS3VIUd"
   },
   "source": [
    "#### Compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1PJfby7yVIUe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(keras.optimizers.Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Egu2lDdHVIUh"
   },
   "source": [
    "# 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_X = \"./data/CH2_training_X.npy\"\n",
    "train_path_y = \"./data/CH2_training_y.npy\"\n",
    "val_path_X = \"./data/CH2_training_X.npy\"\n",
    "val_path_y = \"./data/CH2_training_y.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UxOJOYKSVIUj",
    "outputId": "ea1a905c-932a-4e18-9895-8892835b0069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f47e0dfaae92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_path_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_path_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_path_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_classifier_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/CH2_training.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgen_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-f47e0dfaae92>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path_to_dataset_X, path_to_dataset_y)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meach\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \"\"\"\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_dataset_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0my_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_dataset_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_LABELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/davidelanz/.local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 447\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/davidelanz/.local/lib/python2.7/site-packages/numpy/lib/format.pyc\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def load_dataset(path_to_dataset_X, path_to_dataset_y):\n",
    "    \"\"\"\n",
    "    Load train/validation set from .npy file\n",
    "    Input:\n",
    "        path_to_dataset (str)\n",
    "    Output:\n",
    "        X (np.ndarray): shape (num_samples, image_height, image_width, 1) \n",
    "        y (list): each element is a np.ndarray, shape (num_samples, num_classes)\n",
    "    \"\"\"\n",
    "    X = np.load(path_to_dataset_X)\n",
    "    y_tensor = np.load(path_to_dataset_y)\n",
    "    y = [y_tensor[i, :, :]for i in range(NUM_LABELS)]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "gen_param = {'num_classes': NUM_CLASSES, \n",
    "             'num_labels': NUM_LABELS, \n",
    "             'bins_edge': BINS_EDGE, \n",
    "             'image_shape': IMAGE_SHAPE, \n",
    "             'num_samples': None, \n",
    "             'data_root_dir': \"./data/training_data/\", # path to folder contained images\n",
    "             'flip_prob': 0.5}\n",
    "\n",
    "if os.path.isfile(train_path_X):\n",
    "    print(\"Load dataset\")\n",
    "    X_train, y_train = load_dataset(train_path_X, train_path_y)\n",
    "else:\n",
    "    print(\"Generate dataset\")\n",
    "    X_train, y_train = gen_classifier_dataset(\"./data/CH2_training.csv\", **gen_param)\n",
    "    # save data file for future use\n",
    "    np.save('./data/CH2_training_X.npy', X_train)\n",
    "    np.save('./data/CH2_training_y.npy', y_train)\n",
    "\n",
    "if os.path.isfile(val_path_X):\n",
    "    X_val, y_val = load_dataset(val_path_X, val_path_y)\n",
    "else:\n",
    "    X_val, y_val = gen_classifier_dataset(\"./data/CH2_training.csv\", **gen_param)\n",
    "    np.save('./data/CH2_validation_X.npy', X_val)\n",
    "    np.save('./data/CH2_validation_y.npy', y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adapting dataset to see-1-predict-1 architecture\n",
    "The data is preprared for see-1-predict-5 architecture, so we have 5 labels for each. \n",
    "We will just take the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uyUq4frKbTy4"
   },
   "outputs": [],
   "source": [
    "y_train = y_train[0]\n",
    "y_val = y_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLi_wG4CbZZk"
   },
   "outputs": [],
   "source": [
    "# Integer conversion of the keys from char to integers\n",
    "classes_weight = {}\n",
    "for k in CLASSES_WEIGHT.keys():\n",
    "    classes_weight[int(k)] = CLASSES_WEIGHT[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 14525
    },
    "colab_type": "code",
    "id": "mrhsEKaYW9y5",
    "outputId": "610d9a35-457e-40b5-bdde-cce0b1d7fb16"
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "max_epochs = 1000\n",
    "\n",
    "time_str = time.strftime(\"%Y_%m_%d_%H_%M\")\n",
    "log_dir = './logs/' + time_str\n",
    "\n",
    "# See: https://keras.io/callbacks/#tensorboard\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\n",
    "                                          batch_size=batch_size, \n",
    "                                          update_freq='epoch',\n",
    "                                          histogram_freq = 1,\n",
    "                                          write_images = True) \n",
    "\n",
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n",
    "                                              patience=50,\n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x=X_train,\n",
    "                y=y_train,\n",
    "                epochs=max_epochs,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=[tb_callback, early_stop_cb],\n",
    "                class_weight=classes_weight,\n",
    "                initial_epoch=0,\n",
    "                verbose = 2,\n",
    "                workers = 10,\n",
    "                shuffle=True,\n",
    "                batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JRX0UxKei5D"
   },
   "source": [
    "# 3. Plot Training Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "colab_type": "code",
    "id": "7-91uU1TelSL",
    "outputId": "8f3216e1-995d-4bbc-921b-b5b03a1e9436"
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DXfzEmsEVIUt"
   },
   "source": [
    "# 4. Save the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQW_V8viVIUu"
   },
   "outputs": [],
   "source": [
    "# serialize model to HDF5\n",
    "model.save(log_dir + \"/see_1_predict_1_%s.h5\" % time_str)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "NRq2LuFRVIQP"
   ],
   "name": "resnet8_train.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
