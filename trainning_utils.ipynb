{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import bernoulli\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import Sequence\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, add\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import regularizers, Model\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgCenterCrop(img, crop_size):\n",
    "    \"\"\"\n",
    "    Crop source img\n",
    "    \n",
    "    :param img: source img\n",
    "    \n",
    "    :param crop_size: ints tuple\n",
    "        size of cropped img\n",
    "        \n",
    "    :return: cropped img\n",
    "    \"\"\"\n",
    "    crop_height, crop_width = crop_size \n",
    "    w_l = np.int32((img.shape[1] - crop_width) / 2)\n",
    "    return img[img.shape[0] - crop_height:, w_l: w_l + crop_width]\n",
    "\n",
    "\n",
    "def imgRandomFlip(img, steering_angle, flipping_prob=0.5):\n",
    "    \"\"\"\n",
    "    Flip a coin, if head -> flip the image. If the image is flipped\n",
    "    the steering angle is flipped sign\n",
    "    \n",
    "    :param img: original image\n",
    "    \n",
    "    :param steering_angle: original steering angle\n",
    "    \n",
    "    :param flipping_prob:\n",
    "    \n",
    "    :return:\n",
    "        (flipped) image, (flipped) steering angle\n",
    "    \n",
    "    \"\"\"\n",
    "    head = bernoulli.rvs(flipping_prob)\n",
    "    if head:\n",
    "        return np.fliplr(img), -1 * steering_angle\n",
    "    else:\n",
    "        return img, steering_angle\n",
    "    \n",
    "\n",
    "def imgRandomAdjustGamma(img):\n",
    "    \"\"\"\n",
    "    Randomly apply gamma correction on img to adjust its brightness\n",
    "    \n",
    "    :param img: source image\n",
    "    \"\"\"\n",
    "    gamma = np.random.uniform(0.4, 1.5)\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255\n",
    "                      for i in np.arange(0, 256)]).astype(\"uint8\") \n",
    "    \n",
    "    # apply gamma correction using lookup table\n",
    "    return cv.LUT(img, table)\n",
    "\n",
    "\n",
    "def imgRandomShear(img, steering_angle, shear_range=200):\n",
    "    \"\"\"\n",
    "    Source:  https://medium.com/@ksakmann/behavioral-cloning-make-a-car-drive-like-yourself-dc6021152713#.7k8vfppvk\n",
    "\n",
    "    :param img: source img\n",
    "    \n",
    "    :param steering_angle: associate steering_angle\n",
    "    \n",
    "    :param shear_range: random shear between [-shear_range, shear_range + 1]\n",
    "\n",
    "    :return:\n",
    "        sheared img & sheared steering angle\n",
    "    \"\"\"\n",
    "    if len(img.shape) > 2:\n",
    "        rows, cols, ch = img.shape\n",
    "    else:\n",
    "        rows, cols = img.shape\n",
    "    dx = np.random.randint(-shear_range, shear_range + 1)\n",
    "    random_point = [cols / 2 + dx, rows / 2]\n",
    "    pts1 = np.float32([[0, rows], [cols, rows], [cols / 2, rows / 2]])\n",
    "    pts2 = np.float32([[0, rows], [cols, rows], random_point])\n",
    "    dsteering = dx / (rows / 2) * 360 / (2 * np.pi * 25.0) / 6.0\n",
    "    M = cv.getAffineTransform(pts1, pts2)\n",
    "    img = cv.warpAffine(img, M, (cols, rows), borderMode=1)\n",
    "    steering_angle += dsteering\n",
    "\n",
    "    return img, steering_angle\n",
    "\n",
    "\n",
    "def imgRandomRotate(img, steering_angle, max_rotation=15):\n",
    "    \"\"\"\n",
    "    Rotate input image\n",
    "    \n",
    "    :param img: source img\n",
    "    \n",
    "    :param steering_angle: assoc. steering_angle\n",
    "    \n",
    "    :return:\n",
    "        Rotated img & rotated steering angle\n",
    "    \"\"\"\n",
    "    rot_angle = np.random.uniform(-max_rotation, max_rotation + 1) * np.pi / 180\n",
    "    return rotate(img, rot_angle, reshape=False), steering_angle - rot_angle\n",
    "\n",
    "\n",
    "def imgPreprocess(img, steering_angle, crop_size=(300, 400), shear_prob=0.75, resize=(128, 128)):\n",
    "    \"\"\"\n",
    "    Apply all random treatment on source image\n",
    "    \n",
    "    :return:\n",
    "        pre-processed img & its associate steering angle\n",
    "    \"\"\"\n",
    "    # crop \n",
    "    img = imgCenterCrop(img, crop_size)\n",
    "    \n",
    "    # adjust brightness\n",
    "    img = imgRandomAdjustGamma(img)\n",
    "    \n",
    "    # randomly flip\n",
    "    img, steering_angle = imgRandomFlip(img, steering_angle)\n",
    "    \n",
    "    # randomly rotate\n",
    "    img, steering_angle = imgRandomRotate(img, steering_angle)\n",
    "    \n",
    "    # randomly shear\n",
    "    head = bernoulli.rvs(shear_prob)\n",
    "    if head:\n",
    "        img, steering_angle = imgRandomShear(img, steering_angle)\n",
    "    \n",
    "    # resize \n",
    "    img = np.float32(cv.resize(img, resize))\n",
    "    \n",
    "    if len(img.shape) == 2:\n",
    "        img = img.reshape((resize[0], resize[1], 1))\n",
    "    \n",
    "    return img, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640)\n",
      "(128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "t_img = cv.imread('data/center/1479424215880976321.png', 0)\n",
    "print(t_img.shape)\n",
    "steering_angle = 0\n",
    "img, steering_angle = imgPreprocess(t_img, steering_angle)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEERING_COEFFICIENT = 0.229  # to calculate steering angle associate with (left/ right) camera "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGetImgFiles(df, batch_idx, batch_size=64):\n",
    "    \"\"\"\n",
    "    Extract name of image files & associate steering angle\n",
    "    from dataframe starting from the (batch_idx * batch_size)-th row\n",
    "    \n",
    "    :param df: \n",
    "        dataframe object storing csv file\n",
    "    \n",
    "    :param batch_idx: int\n",
    "        which rows to start getting img path & steering angle\n",
    "        \n",
    "    :param batch_size:\n",
    "        \n",
    "    :return:\n",
    "        List of tuples of frame_id(which camera), img_path & steering angle\n",
    "    \"\"\"\n",
    "    path_prefix = 'data/'\n",
    "    _batch = []\n",
    "    row_0 = batch_idx * batch_size\n",
    "    for i in range(min(batch_size, len(df) - row_0)):\n",
    "        frame_id = df.loc[row_0 + i].frame_id\n",
    "        img_path = path_prefix + df.loc[row_0 + i].filename\n",
    "        steering_angle = df.loc[row_0 + i].angle\n",
    "        _batch.append((frame_id, img_path, steering_angle))\n",
    "\n",
    "    return _batch\n",
    "\n",
    "\n",
    "def trainGenerateBatch(df, batch_idx, batch_size=64, resize=(128, 128), color_mode=0):\n",
    "    \"\"\"\n",
    "    Generate batch for training.\n",
    "    \n",
    "    :param df: \n",
    "        dataframe object storing csv file\n",
    "    \n",
    "    :param batch_idx: int\n",
    "        which rows to start getting img path & steering angle\n",
    "        \n",
    "    :param batch_size:\n",
    "    \n",
    "    :param color_mode:\n",
    "        1: color img, 0: grayscale img \n",
    "        \n",
    "    :return:\n",
    "        1 array of preprocessid imgs & 1 array assoc. steering angle\n",
    "    \"\"\"\n",
    "    # read csv & extract frame_id, path to img file, steering angle\n",
    "    _batch = trainGetImgFiles(df, batch_idx, batch_size)\n",
    "    \n",
    "    batch_X = []  # features\n",
    "    batch_y = []  # labels\n",
    "    \n",
    "    # preprocess img & steering angle \n",
    "    for _frame_id, _path, _steering in _batch:\n",
    "        # get raw image\n",
    "        _img = cv.imread(_path, color_mode)  \n",
    "        \n",
    "        # adjust steering angle if img is obtained by side camera\n",
    "        if _frame_id == 'left_camera':\n",
    "            _steering -= STEERING_COEFFICIENT\n",
    "        elif _frame_id == 'right_camera':\n",
    "            _steering += STEERING_COEFFICIENT\n",
    "        \n",
    "        # manipulate img & steering \n",
    "        img, steering = imgPreprocess(_img, _steering, resize=resize)\n",
    "        \n",
    "        batch_X.append(img)\n",
    "        batch_y.append(steering)\n",
    "    \n",
    "    return np.array(batch_X), np.array(batch_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data_file, batch_size=64, color_mode=0, img_size=(128, 128), shuffle=True, \n",
    "                 is_training=True):\n",
    "        \"\"\"\n",
    "        :param data_file:\n",
    "            name of csv file contains driving info\n",
    "            \n",
    "        :param batch_size: int\n",
    "        \n",
    "        :param img_size: tuple of ints\n",
    "            size of training & testing img\n",
    "        \n",
    "        :param shuffle: bool\n",
    "            shuffle training & validation set after every epoch\n",
    "            \n",
    "        :param is_training: bool\n",
    "            generate data for training or testing\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(data_file)  # dataframe\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.color_mode = color_mode\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.is_training = is_training\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        :return:\n",
    "            Number of batches per epoch\n",
    "        \"\"\"\n",
    "        return int(np.floor(len(self.df) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generate 1 batch of data\n",
    "        \n",
    "        :param idx: int\n",
    "            starting idx of this batch\n",
    "        \"\"\"\n",
    "        if self.is_training:\n",
    "            return trainGenerateBatch(self.df, idx, self.batch_size, self.img_size, self.color_mode)\n",
    "        else:\n",
    "            return testGenerateBatch(self.df, idx, self.batch_size, self.img_size, self.color_mode)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - Learn to Fly by Driving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet8(img_width, img_height, img_channels, output_dim):\n",
    "    \"\"\"\n",
    "    Define model architecture.\n",
    "    \n",
    "    # Arguments\n",
    "       img_width: Target image widht.\n",
    "       img_height: Target image height.\n",
    "       img_channels: Target image channels.\n",
    "       output_dim: Dimension of model output.\n",
    "       \n",
    "    # Returns\n",
    "       model: A Model instance.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input\n",
    "    img_input = Input(shape=(img_height, img_width, img_channels))\n",
    "\n",
    "    x1 = Conv2D(32, (5, 5), strides=[2,2], padding='same')(img_input)\n",
    "    x1 = MaxPooling2D(pool_size=(3, 3), strides=[2,2])(x1)\n",
    "\n",
    "    # First residual block\n",
    "    x2 = BatchNormalization()(x1)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = Conv2D(32, (3, 3), strides=[2,2], padding='same',\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                kernel_regularizer=regularizers.l2(1e-4))(x2)\n",
    "\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = Conv2D(32, (3, 3), padding='same',\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                kernel_regularizer=regularizers.l2(1e-4))(x2)\n",
    "\n",
    "    x1 = Conv2D(32, (1, 1), strides=[2,2], padding='same')(x1)\n",
    "    x3 = add([x1, x2])\n",
    "\n",
    "    # Second residual block\n",
    "    x4 = BatchNormalization()(x3)\n",
    "    x4 = Activation('relu')(x4)\n",
    "    x4 = Conv2D(64, (3, 3), strides=[2,2], padding='same',\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                kernel_regularizer=regularizers.l2(1e-4))(x4)\n",
    "\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = Activation('relu')(x4)\n",
    "    x4 = Conv2D(64, (3, 3), padding='same',\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                kernel_regularizer=regularizers.l2(1e-4))(x4)\n",
    "\n",
    "    x3 = Conv2D(64, (1, 1), strides=[2,2], padding='same')(x3)\n",
    "    x5 = add([x3, x4])\n",
    "\n",
    "    # Third residual block\n",
    "    x6 = BatchNormalization()(x5)\n",
    "    x6 = Activation('relu')(x6)\n",
    "    x6 = Conv2D(128, (3, 3), strides=[2,2], padding='same',\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                kernel_regularizer=regularizers.l2(1e-4))(x6)\n",
    "\n",
    "    x6 = BatchNormalization()(x6)\n",
    "    x6 = Activation('relu')(x6)\n",
    "    x6 = Conv2D(128, (3, 3), padding='same',\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                kernel_regularizer=regularizers.l2(1e-4))(x6)\n",
    "\n",
    "    x5 = Conv2D(128, (1, 1), strides=[2,2], padding='same')(x5)\n",
    "    x7 = add([x5, x6])\n",
    "\n",
    "    x = Flatten()(x7)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Steering channel\n",
    "    steer = Dense(output_dim)(x)\n",
    "\n",
    "    # Define steering-collision model\n",
    "    model = Model(inputs=[img_input], outputs=[steer])\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 64, 64, 32)   832         <tensorflow.python.keras.engine.i\n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 31, 31, 32)   0           <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_25 (Batc (None, 31, 31, 32)   128         <tensorflow.python.keras.layers.p\n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 31, 31, 32)   0           <tensorflow.python.keras.layers.n\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 32)   9248        <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_26 (Batc (None, 16, 16, 32)   128         <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 32)   0           <tensorflow.python.keras.layers.n\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 32)   1056        <tensorflow.python.keras.layers.p\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 32)   9248        <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 32)   0           <tensorflow.python.keras.layers.c\n",
      "                                                                 <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_27 (Batc (None, 16, 16, 32)   128         <tensorflow.python.keras.layers.m\n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 32)   0           <tensorflow.python.keras.layers.n\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 64)     18496       <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_28 (Batc (None, 8, 8, 64)     256         <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 64)     0           <tensorflow.python.keras.layers.n\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 8, 8, 64)     2112        <tensorflow.python.keras.layers.m\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 64)     36928       <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 64)     0           <tensorflow.python.keras.layers.c\n",
      "                                                                 <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_29 (Batc (None, 8, 8, 64)     256         <tensorflow.python.keras.layers.m\n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 64)     0           <tensorflow.python.keras.layers.n\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 128)    73856       <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_30 (Batc (None, 4, 4, 128)    512         <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 4, 4, 128)    0           <tensorflow.python.keras.layers.n\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 4, 4, 128)    8320        <tensorflow.python.keras.layers.m\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 4, 4, 128)    147584      <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 4, 4, 128)    0           <tensorflow.python.keras.layers.c\n",
      "                                                                 <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2048)         0           <tensorflow.python.keras.layers.m\n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 2048)         0           <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 2048)         0           <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            2049        <tensorflow.python.keras.layers.c\n",
      "==================================================================================================\n",
      "Total params: 311,137\n",
      "Trainable params: 310,433\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = resnet8(128, 128, 1, 1)\n",
    "model.compile(optimizer=optimizers.Adam(decay=1e-5), loss=\"mse\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 147s 1s/step - loss: 29.1167 - val_loss: 1.0386\n"
     ]
    }
   ],
   "source": [
    "# create two generators for training and validation\n",
    "train_gen = DataGenerator('data/ch2_training.csv')\n",
    "validation_gen = DataGenerator('data/ch2_validation.csv')\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                              epochs=1,\n",
    "                              validation_data=validation_gen,\n",
    "                              verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testGenerateBatch(df, batch_idx, batch_size=64, resize=(128, 128), color_mode=0):\n",
    "    \"\"\"\n",
    "    Generate batch for testing\n",
    "    from dataframe starting from the (batch_idx * batch_size)-th row\n",
    "    \n",
    "    :param df: \n",
    "        dataframe object storing csv file\n",
    "    \n",
    "    :param batch_idx: int\n",
    "        which rows to start getting img path & steering angle\n",
    "        \n",
    "    :param batch_size:\n",
    "        \n",
    "    :return:\n",
    "        List of tuples of img_path & steering angle\n",
    "    \"\"\"\n",
    "    path_prefix = 'data_test/center/'\n",
    "    path_suffix = '.jpg'\n",
    "    \n",
    "    batch_X = []  # features\n",
    "    batch_y = []  # labels\n",
    "    \n",
    "    row_0 = batch_idx * batch_size\n",
    "    for i in range(min(batch_size, len(df) - row_0)):\n",
    "        # get image\n",
    "        img_path = path_prefix + df['frame_id'][i].astype(str) + path_suffix\n",
    "        img = cv.imread(img_path, color_mode)\n",
    "        \n",
    "        # resize & reshape  \n",
    "        img = np.float32(cv.resize(img, resize))\n",
    "        if len(img.shape) == 2:\n",
    "            img = img.reshape((resize[0], resize[1], 1))\n",
    "        \n",
    "        # get steering_angle        \n",
    "        steering_angle = df.loc[row_0 + i].steering_angle\n",
    "        \n",
    "        batch_X.append(img)\n",
    "        batch_y.append(steering_angle)\n",
    "        \n",
    "    return np.array(batch_X), np.array(batch_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/87 [============================>.] - ETA: 0s - loss: 1.2309"
     ]
    }
   ],
   "source": [
    "test_gen = DataGenerator('data_test/final_example.csv', is_training=False)\n",
    "\n",
    "\n",
    "test_diary = model.evaluate_generator(test_gen,\n",
    "                                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
