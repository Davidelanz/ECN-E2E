{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "import keras.layers as KL\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "from training_utils import gen_classifier_dataset\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (200, 200, 1)\n",
    "NUM_LABELS = 5\n",
    "BINS_EDGE = np.load(\"./data/bins_edge.npy\")\n",
    "NUM_CLASSES = len(BINS_EDGE) - 1  \n",
    "\n",
    "with open('./data/classes_weight.json', 'r') as fp:\n",
    "    CLASSES_WEIGHT = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model Architect\n",
    "## 1.1 ResNet Block\n",
    "Definition of ResNet block is adapted from https://github.com/uzh-rpg/rpg_public_dronet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convolutional_block(X, num_filters, shape_filters, strides, stage):\n",
    "    \"\"\"\n",
    "    Implementation of convolutional block in Residual network\n",
    "    \n",
    "    Input:\n",
    "        X (tensor): input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "        num_filters (list of 3 ints): list of number of filters\n",
    "        shape_filters (list of 3 ints): list of filters' shape\n",
    "        strides (list of 3 ints): list of strides\n",
    "        stage (int): stage of this convolutional block in the whole ResNet\n",
    "        \n",
    "    Output:\n",
    "        tensor of shape (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # retrieve filters shape from filters\n",
    "    n1, n2, n3 = num_filters\n",
    "    f1, f2, f3 = shape_filters\n",
    "    \n",
    "    # retrieve strides from strides\n",
    "    s1, s2, s3 = strides\n",
    "    \n",
    "    # create name\n",
    "    bn_name_base = 'bn_' + str(stage) + '_'\n",
    "    conv_name_base = 'conv_' + str(stage) + '_'\n",
    "    \n",
    "    # save value of X\n",
    "    X_shorcut = X\n",
    "    \n",
    "    # First component of the main path\n",
    "    X = BatchNormalization(name=bn_name_base + 'a')(X)\n",
    "    X = Activation('relu', name=\"feature_map_%d\" % (stage - 1))(X)\n",
    "    X = Conv2D(n1, (f1, f1), strides=[s1, s1], padding='same',\n",
    "               name=conv_name_base + 'a')(X)\n",
    "    \n",
    "    # Second component of the main path\n",
    "    X = BatchNormalization(name=bn_name_base + 'b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(n2, (f2, f2), strides=[s2, s2], padding='same',\n",
    "               name=conv_name_base + 'b')(X)\n",
    "    \n",
    "    # Short-cut\n",
    "    X_shorcut = Conv2D(n3, (f3, f3), strides=[s3, s3], padding='same', \n",
    "                       name=conv_name_base + 'c')(X_shorcut)\n",
    "    \n",
    "    X = KL.merge.add([X, X_shorcut])\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_model(input_shape):\n",
    "    \"\"\"\n",
    "    Define encoder architecture as ResNet8\n",
    "    \n",
    "    Input:\n",
    "        input_shape (list of ints): shape of input image [n_H, n_W, n_C]\n",
    "        \n",
    "    Output:\n",
    "        model: a Model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input\n",
    "    X_input = Input(shape=input_shape)\n",
    "    \n",
    "    # Apply 1st convolution & max pooling on input\n",
    "    X = Conv2D(32, (5, 5), strides=[2,2], padding='same', name='conv_0')(X_input)\n",
    "    X = MaxPooling2D(pool_size=(3, 3), strides=[2,2])(X) \n",
    "    \n",
    "    # First convolutional block\n",
    "    X = convolutional_block(X, [32, 32, 32], [3, 3, 1], [2, 1, 2], stage=1)\n",
    "    \n",
    "    # Second convolutional block\n",
    "    X = convolutional_block(X, [64, 64, 64], [3, 3, 1], [2, 1, 2], stage=2)\n",
    "    \n",
    "    # Third convolutional block\n",
    "    X = convolutional_block(X, [128, 128, 128], [3, 3, 1], [2, 1, 2], stage=3)\n",
    "    \n",
    "    # Output layer of resnet-8\n",
    "    X = Flatten()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # extract feature vector\n",
    "    X_feature = Dropout(0.5)(X)\n",
    "    \n",
    "    # extract feature vector\n",
    "    X_feature = Dropout(0.5)(X)\n",
    "    \n",
    "    # apply classifier head\n",
    "    y = []\n",
    "    for i in range(NUM_LABELS):\n",
    "        # apply classifier body\n",
    "        X_body = Dense(800, activation='relu')(X_feature)\n",
    "        X_body_1 = Dropout(0.5)(X_body)\n",
    "        out = Dense(NUM_CLASSES, activation='softmax', name=\"head_%d\" % i)(X_body_1)\n",
    "        y.append(out)\n",
    "    \n",
    "    model = Model(inputs=[X_input], outputs=y)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py:210: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200, 200, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv2D)                 (None, 100, 100, 32) 832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 49, 49, 32)   0           conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_a (BatchNormalization)     (None, 49, 49, 32)   128         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "feature_map_0 (Activation)      (None, 49, 49, 32)   0           bn_1_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_a (Conv2D)               (None, 25, 25, 32)   9248        feature_map_0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_b (BatchNormalization)     (None, 25, 25, 32)   128         conv_1_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 25, 25, 32)   0           bn_1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_b (Conv2D)               (None, 25, 25, 32)   9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_c (Conv2D)               (None, 25, 25, 32)   1056        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 25, 32)   0           conv_1_b[0][0]                   \n",
      "                                                                 conv_1_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_a (BatchNormalization)     (None, 25, 25, 32)   128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "feature_map_1 (Activation)      (None, 25, 25, 32)   0           bn_2_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_a (Conv2D)               (None, 13, 13, 64)   18496       feature_map_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn_2_b (BatchNormalization)     (None, 13, 13, 64)   256         conv_2_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 13, 13, 64)   0           bn_2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_b (Conv2D)               (None, 13, 13, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_c (Conv2D)               (None, 13, 13, 64)   2112        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 13, 13, 64)   0           conv_2_b[0][0]                   \n",
      "                                                                 conv_2_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bn_3_a (BatchNormalization)     (None, 13, 13, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "feature_map_2 (Activation)      (None, 13, 13, 64)   0           bn_3_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_a (Conv2D)               (None, 7, 7, 128)    73856       feature_map_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn_3_b (BatchNormalization)     (None, 7, 7, 128)    512         conv_3_a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 7, 7, 128)    0           bn_3_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_b (Conv2D)               (None, 7, 7, 128)    147584      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_c (Conv2D)               (None, 7, 7, 128)    8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 7, 7, 128)    0           conv_3_b[0][0]                   \n",
      "                                                                 conv_3_c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6272)         0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 6272)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 6272)         0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 800)          5018400     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 800)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 800)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 800)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 800)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 800)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 800)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 800)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 800)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 800)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 800)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "head_0 (Dense)                  (None, 114)          91314       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "head_1 (Dense)                  (None, 114)          91314       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "head_2 (Dense)                  (None, 114)          91314       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "head_3 (Dense)                  (None, 114)          91314       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "head_4 (Dense)                  (None, 114)          91314       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "head_5 (Dense)                  (None, 114)          91314       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "head_6 (Dense)                  (None, 114)          91314       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "head_7 (Dense)                  (None, 114)          91314       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "head_8 (Dense)                  (None, 114)          91314       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "head_9 (Dense)                  (None, 114)          91314       dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 6,240,628\n",
      "Trainable params: 6,239,924\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = full_model(IMAGE_SHAPE)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss=\"categorical_crossentropy\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_X = \"./data/CH2_training_X.npy\"\n",
    "train_path_y = \"./data/CH2_training_y.npy\"\n",
    "val_path_X = \"./data/CH2_validation_X.npy\"\n",
    "val_path_y = \"./data/CH2_validation_y.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path_to_dataset_X, path_to_dataset_y):\n",
    "    \"\"\"\n",
    "    Load train/validation set from .npy file\n",
    "    Input:\n",
    "        path_to_dataset (str)\n",
    "    Output:\n",
    "        X (np.ndarray): shape (num_samples, image_height, image_width, 1) \n",
    "        y (list): each element is a np.ndarray, shape (num_samples, num_classes)\n",
    "    \"\"\"\n",
    "    X = np.load(path_to_dataset_X)\n",
    "    y_tensor = np.load(path_to_dataset_y)\n",
    "    y = [y_tensor[i, :, :]for i in range(NUM_LABELS)]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "gen_param = {'num_classes': NUM_CLASSES, \n",
    "             'num_labels': NUM_LABELS, \n",
    "             'bins_edge': BINS_EDGE, \n",
    "             'image_shape': IMAGE_SHAPE, \n",
    "             'num_samples': None, \n",
    "             'data_root_dir': \"./data/training_data/center/\", # path to folder contained images\n",
    "             'flip_prob': 0.5}\n",
    "\n",
    "if os.path.isfile(train_path_X):\n",
    "    print(\"Load dataset\")\n",
    "    X_train, y_train = load_dataset(train_path_X, train_path_y)\n",
    "else:\n",
    "    print(\"Generate dataset\")\n",
    "    X_train, y_train = gen_classifier_dataset(\"./data/CH2_training.csv\", **gen_param)\n",
    "    # save data file for future use\n",
    "    np.save('./data/CH2_training_X.npy', X_train)\n",
    "    np.save('./data/CH2_training_y.npy', y_train)\n",
    "\n",
    "if os.path.isfile(val_path_X):\n",
    "    X_val, y_val = load_dataset(val_path_X, val_path_y)\n",
    "else:\n",
    "    X_val, y_val = gen_classifier_dataset(\"./data/CH2_validation.csv\", **gen_param)\n",
    "    np.save('./data/CH2_validation_X.npy', X_val)\n",
    "    np.save('./data/CH2_validation_y.npy', y_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3067: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 18183 samples, validate on 2021 samples\n",
      "Epoch 1/50\n",
      "18183/18183 [==============================] - 48s 3ms/step - loss: 75.2002 - head_0_loss: 7.2896 - head_1_loss: 7.5561 - head_2_loss: 7.1665 - head_3_loss: 7.2296 - head_4_loss: 7.9905 - head_5_loss: 7.8807 - head_6_loss: 7.3873 - head_7_loss: 8.2520 - head_8_loss: 7.2345 - head_9_loss: 7.2135 - head_0_acc: 0.1900 - head_1_acc: 0.1557 - head_2_acc: 0.1918 - head_3_acc: 0.1902 - head_4_acc: 0.1355 - head_5_acc: 0.1595 - head_6_acc: 0.1828 - head_7_acc: 0.1283 - head_8_acc: 0.1971 - head_9_acc: 0.1896 - val_loss: 29.5784 - val_head_0_loss: 2.9701 - val_head_1_loss: 2.9698 - val_head_2_loss: 2.9502 - val_head_3_loss: 2.9412 - val_head_4_loss: 2.9500 - val_head_5_loss: 2.9544 - val_head_6_loss: 2.9581 - val_head_7_loss: 2.9746 - val_head_8_loss: 2.9468 - val_head_9_loss: 2.9632 - val_head_0_acc: 0.2237 - val_head_1_acc: 0.2246 - val_head_2_acc: 0.2237 - val_head_3_acc: 0.2172 - val_head_4_acc: 0.2232 - val_head_5_acc: 0.2237 - val_head_6_acc: 0.2350 - val_head_7_acc: 0.2291 - val_head_8_acc: 0.2286 - val_head_9_acc: 0.2118\n",
      "Epoch 2/50\n",
      "18183/18183 [==============================] - 44s 2ms/step - loss: 27.2694 - head_0_loss: 2.7464 - head_1_loss: 2.7292 - head_2_loss: 2.7235 - head_3_loss: 2.7025 - head_4_loss: 2.7112 - head_5_loss: 2.7097 - head_6_loss: 2.7077 - head_7_loss: 2.7343 - head_8_loss: 2.7459 - head_9_loss: 2.7590 - head_0_acc: 0.2275 - head_1_acc: 0.2274 - head_2_acc: 0.2323 - head_3_acc: 0.2362 - head_4_acc: 0.2345 - head_5_acc: 0.2378 - head_6_acc: 0.2388 - head_7_acc: 0.2409 - head_8_acc: 0.2298 - head_9_acc: 0.2295 - val_loss: 23.8609 - val_head_0_loss: 2.4103 - val_head_1_loss: 2.3775 - val_head_2_loss: 2.3555 - val_head_3_loss: 2.3323 - val_head_4_loss: 2.3453 - val_head_5_loss: 2.3582 - val_head_6_loss: 2.3734 - val_head_7_loss: 2.4084 - val_head_8_loss: 2.4350 - val_head_9_loss: 2.4650 - val_head_0_acc: 0.2885 - val_head_1_acc: 0.2924 - val_head_2_acc: 0.2954 - val_head_3_acc: 0.3097 - val_head_4_acc: 0.2964 - val_head_5_acc: 0.3073 - val_head_6_acc: 0.2984 - val_head_7_acc: 0.2914 - val_head_8_acc: 0.2845 - val_head_9_acc: 0.2855\n",
      "Epoch 3/50\n",
      "18183/18183 [==============================] - 45s 2ms/step - loss: 22.4207 - head_0_loss: 2.2881 - head_1_loss: 2.2403 - head_2_loss: 2.2003 - head_3_loss: 2.1774 - head_4_loss: 2.1791 - head_5_loss: 2.1892 - head_6_loss: 2.2160 - head_7_loss: 2.2635 - head_8_loss: 2.3187 - head_9_loss: 2.3482 - head_0_acc: 0.2909 - head_1_acc: 0.2968 - head_2_acc: 0.3056 - head_3_acc: 0.3113 - head_4_acc: 0.3116 - head_5_acc: 0.3133 - head_6_acc: 0.3121 - head_7_acc: 0.3037 - head_8_acc: 0.2962 - head_9_acc: 0.2915 - val_loss: 20.0880 - val_head_0_loss: 2.0752 - val_head_1_loss: 2.0128 - val_head_2_loss: 1.9582 - val_head_3_loss: 1.9133 - val_head_4_loss: 1.9135 - val_head_5_loss: 1.9440 - val_head_6_loss: 1.9929 - val_head_7_loss: 2.0405 - val_head_8_loss: 2.0928 - val_head_9_loss: 2.1449 - val_head_0_acc: 0.3528 - val_head_1_acc: 0.3691 - val_head_2_acc: 0.3617 - val_head_3_acc: 0.3805 - val_head_4_acc: 0.3953 - val_head_5_acc: 0.3815 - val_head_6_acc: 0.3652 - val_head_7_acc: 0.3726 - val_head_8_acc: 0.3652 - val_head_9_acc: 0.3459\n",
      "Epoch 4/50\n",
      "18183/18183 [==============================] - 45s 2ms/step - loss: 19.4074 - head_0_loss: 2.0113 - head_1_loss: 1.9459 - head_2_loss: 1.8944 - head_3_loss: 1.8578 - head_4_loss: 1.8433 - head_5_loss: 1.8636 - head_6_loss: 1.9026 - head_7_loss: 1.9673 - head_8_loss: 2.0276 - head_9_loss: 2.0937 - head_0_acc: 0.3497 - head_1_acc: 0.3590 - head_2_acc: 0.3663 - head_3_acc: 0.3717 - head_4_acc: 0.3784 - head_5_acc: 0.3796 - head_6_acc: 0.3785 - head_7_acc: 0.3670 - head_8_acc: 0.3558 - head_9_acc: 0.3388 - val_loss: 18.0307 - val_head_0_loss: 1.8867 - val_head_1_loss: 1.7977 - val_head_2_loss: 1.7522 - val_head_3_loss: 1.6871 - val_head_4_loss: 1.6971 - val_head_5_loss: 1.7215 - val_head_6_loss: 1.7829 - val_head_7_loss: 1.8336 - val_head_8_loss: 1.9071 - val_head_9_loss: 1.9650 - val_head_0_acc: 0.3953 - val_head_1_acc: 0.4216 - val_head_2_acc: 0.4122 - val_head_3_acc: 0.4201 - val_head_4_acc: 0.4448 - val_head_5_acc: 0.4176 - val_head_6_acc: 0.4142 - val_head_7_acc: 0.3998 - val_head_8_acc: 0.3845 - val_head_9_acc: 0.3726\n",
      "Epoch 5/50\n",
      "18183/18183 [==============================] - 44s 2ms/step - loss: 17.7142 - head_0_loss: 1.8801 - head_1_loss: 1.7912 - head_2_loss: 1.7157 - head_3_loss: 1.6829 - head_4_loss: 1.6616 - head_5_loss: 1.6785 - head_6_loss: 1.7192 - head_7_loss: 1.7883 - head_8_loss: 1.8642 - head_9_loss: 1.9324 - head_0_acc: 0.3833 - head_1_acc: 0.4020 - head_2_acc: 0.4169 - head_3_acc: 0.4235 - head_4_acc: 0.4323 - head_5_acc: 0.4283 - head_6_acc: 0.4281 - head_7_acc: 0.4128 - head_8_acc: 0.3984 - head_9_acc: 0.3850 - val_loss: 16.0386 - val_head_0_loss: 1.7415 - val_head_1_loss: 1.6298 - val_head_2_loss: 1.5413 - val_head_3_loss: 1.4788 - val_head_4_loss: 1.4738 - val_head_5_loss: 1.4917 - val_head_6_loss: 1.5660 - val_head_7_loss: 1.6336 - val_head_8_loss: 1.7103 - val_head_9_loss: 1.7719 - val_head_0_acc: 0.4201 - val_head_1_acc: 0.4429 - val_head_2_acc: 0.4537 - val_head_3_acc: 0.4755 - val_head_4_acc: 0.4983 - val_head_5_acc: 0.4775 - val_head_6_acc: 0.4582 - val_head_7_acc: 0.4419 - val_head_8_acc: 0.4275 - val_head_9_acc: 0.4122\n",
      "Epoch 6/50\n",
      " 3000/18183 [===>..........................] - ETA: 35s - loss: 16.5297 - head_0_loss: 1.7892 - head_1_loss: 1.7002 - head_2_loss: 1.6072 - head_3_loss: 1.5647 - head_4_loss: 1.5580 - head_5_loss: 1.5653 - head_6_loss: 1.5900 - head_7_loss: 1.6444 - head_8_loss: 1.7206 - head_9_loss: 1.7901 - head_0_acc: 0.4037 - head_1_acc: 0.4340 - head_2_acc: 0.4430 - head_3_acc: 0.4597 - head_4_acc: 0.4533 - head_5_acc: 0.4590 - head_6_acc: 0.4610 - head_7_acc: 0.4447 - head_8_acc: 0.4247 - head_9_acc: 0.4217"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-069772e859b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                   \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                   callbacks=[tb_callback, early_stop_cb])\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# eva_data = eva_metric.get_data()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    183\u001b[0m                         \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                         ins_batch = slice_arrays(\n\u001b[0;32m--> 185\u001b[0;31m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[0m\u001b[1;32m    186\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "\n",
    "time_str = time.strftime(\"%Y_%m_%d_%H_%M\")\n",
    "log_dir = './logs/' + time_str\n",
    "\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir=log_dir,  \n",
    "                                          batch_size=batch_size, \n",
    "                                          update_freq='epoch')\n",
    "\n",
    "early_stop_cb = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                              patience=3,\n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x=X_train,\n",
    "                  y=y_train,\n",
    "                  epochs=50,\n",
    "                  validation_data=(X_val, y_val),\n",
    "                  class_weight=CLASSES_WEIGHT,\n",
    "                  initial_epoch=0,\n",
    "                  shuffle=True,\n",
    "                  batch_size=batch_size,\n",
    "                  callbacks=[tb_callback, early_stop_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Plot Training Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to HDF5\n",
    "model.save(log_dir + \"/s1p5_model_%s.h5\" % time_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
